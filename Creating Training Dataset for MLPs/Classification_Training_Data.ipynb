{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creating_training_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQz4CnSA8BpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Libraries\n",
        "import sys\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd \n",
        "import statistics as st\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import KFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import collections\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.io import arff \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, roc_auc_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt8ElV428K3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlB_UxuM8MvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#functions to read in and clean data\n",
        "def labelencode(data):\n",
        "  \"\"\"encodes the Y into 0 and 1\"\"\"\n",
        "    labelencoder = LabelEncoder()\n",
        "    #Assigning numerical values and storing in another column\n",
        "    Y = data.iloc[:,-1]\n",
        "    Y = labelencoder.fit_transform(Y)\n",
        "    return Y\n",
        "def get_data(list_of_files):\n",
        "  \"\"\"creates two lists and appends all the datasets and their Y variable respectively \"\"\"\n",
        "  X_ls = []\n",
        "  Y_ls = []\n",
        "  for filename in list_of_files:\n",
        "      df = pd.read_csv(filename)\n",
        "      Y = labelencode(df)\n",
        "      X = df.iloc[:,:-1]\n",
        "      X = X._get_numeric_data()\n",
        "      Y_ls.append(Y)\n",
        "      X_ls.append(X)\n",
        "  return(X_ls, Y_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQjx3Ysh8ONF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification Models\n",
        "\n",
        "def random_forest(data, labels):\n",
        "  \"\"\"Takes data(X) and labels(Y) and fits a random forest model with maximum depth 3, using \n",
        "  cross validation with 5 folds and returns the mean f1 score\"\"\"\n",
        "  rfc = RandomForestClassifier(max_depth=3, random_state=0)\n",
        "  score = cross_val_score(rfc, data, labels, cv=5, scoring='f1')\n",
        "  score = np.mean(score)\n",
        "  return(score)\n",
        "  \n",
        "def rf_smote(x_train, y_train):\n",
        "  \"\"\"applies random forest model on x train and y train using SMOTE only on the\n",
        "   training data in the cross validation\"\"\"\n",
        "  imba_pipeline = make_pipeline(SMOTE(random_state=42), \n",
        "                                RandomForestClassifier(max_depth=3, random_state=0))\n",
        "  score = cross_val_score(imba_pipeline, x_train, y_train, scoring='f1', cv=5)\n",
        "  score = np.mean(score)\n",
        "  return(score) \n",
        "  \n",
        "def log_reg(max_iter, X, Y):\n",
        "  \"\"\"Applies logistic regression given x features and vector y of labels using \n",
        "  cross validation with 5 folds and returns the mean f1 score \"\"\"\n",
        "  logisticRegr = LogisticRegression(max_iter=max_iter, solver=\"liblinear\", random_state=0)\n",
        "  score = cross_val_score(logisticRegr, X, Y, cv=5, scoring='f1')\n",
        "  score = np.mean(score)\n",
        "  return(score)\n",
        "  \n",
        "def lr_smote(x_train, y_train):\n",
        "  \"\"\"Applies logistic regression given x features and vector y of labels using SMOTE, \n",
        "  cross validation with 5 folds and returns the mean f1 score \"\"\"\n",
        "  imba_pipeline = make_pipeline(SMOTE(random_state=42), LogisticRegression(max_iter=500, solver=\"liblinear\", random_state=0))\n",
        "  score = cross_val_score(imba_pipeline, x_train, y_train, scoring='f1', cv=5)\n",
        "  score = np.mean(score)\n",
        "  return(score) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBHdhAd18Pze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Automating the feature transformations\n",
        "\n",
        "def feature_trans(y, data, features_list, perc,transformation, imb):\n",
        "  \"\"\"applies a transformation for each feature in the data and evaluates the model before and after applying the transformation,\n",
        "  returns two lists of the names of the features that were classified as either positive or negatiive training samples\"\"\"\n",
        "  \n",
        "  pos_samples= []\n",
        "  neg_samples = []\n",
        "  \n",
        "  if imb == 'sm':\n",
        "    original_score = lr_smote(data,y)\n",
        "  else:\n",
        "    original_score = log_reg(data, y)\n",
        "  \n",
        "  threshold = perc\n",
        "\n",
        "  for col in features_list:\n",
        "    if transformation == 'sqr':  \n",
        "      x = square_root(data, col)\n",
        "    elif transformation == 'square':\n",
        "      x = square(data, col)\n",
        "    elif transformation == 'freq':\n",
        "      x = freq(data, col)\n",
        "    elif transformation == 'log':\n",
        "      x = log(data,col)\n",
        "    elif transformation == 'sig':\n",
        "      x = sigmoid(data, col)\n",
        "    else:\n",
        "      raise RuntimeError('No specified transformation!')\n",
        "\n",
        "    if imb == 'sm':\n",
        "      new_score = lr_smote(x,y)\n",
        "    else:\n",
        "      new_score = log_reg(x, y)\n",
        "    \n",
        "    if round(new_score, 3) - round(original_score, 3) >= threshold:\n",
        "      pos_samples.append(col)\n",
        "    else:\n",
        "      neg_samples.append(col)\n",
        "          \n",
        "  positive_samples = [y for x in pos_samples for y in x]\n",
        "  negative_samples = [y for x in neg_samples for y in x]\n",
        "  \n",
        "  return(positive_samples, negative_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCoVosTuF2uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Percentile Binning\n",
        "def make_seq(inc):\n",
        "  \"\"\"creates a sequence of numbers between 0 and 100, and increments it by the specified inc\"\"\"\n",
        "  x = []\n",
        "  start = 0\n",
        "  end = 100\n",
        "\n",
        "  while start < end:\n",
        "    start += inc \n",
        "    start = round(start,2)\n",
        "    x.append(start)\n",
        "  return(x)\n",
        "\n",
        "def binning_quantile(features_list, data, y, class_, bins):\n",
        "    \"\"\"creates a feature representation of the features in the feature list using\n",
        "    quantiles by binning all the values lower than a given quantile into one bin, returns\n",
        "    a list of the fixed-size arrays of features along with their label as positive or negative samples\"\"\"\n",
        "  b = {\"bin_edges\":[], \"class\": []}\n",
        "  quantiles = make_seq(0.5)\n",
        "\n",
        "  for feature in features_list:\n",
        "\n",
        "    data_feature = list(data[feature])\n",
        "    x_f_pos = [z for x,z in enumerate(data_feature) if y[x] ==1]\n",
        "    x_f_neg = [z for x,z in enumerate(data_feature) if y[x] ==0]\n",
        "\n",
        "    x_f_pos = np.array(x_f_pos).reshape(-1,1)\n",
        "    x_f_neg = np.array(x_f_neg).reshape(-1,1)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "    scaler = scaler.fit(x_f_pos)\n",
        "    x_f_pos = scaler.transform(x_f_pos)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "    scaler = scaler.fit(x_f_neg)\n",
        "    x_f_neg = scaler.transform(x_f_neg)\n",
        "\n",
        "    bin_pos = []\n",
        "    bin_neg = []\n",
        "    \n",
        "    for quant in quantiles:\n",
        "      bin_pos.append(np.percentile(x_f_pos, quant))\n",
        "      bin_neg.append(np.percentile(x_f_neg, quant))\n",
        "      \n",
        "    bin_all = []\n",
        "    bin_all.extend(bin_pos)\n",
        "    bin_all.extend(bin_neg)\n",
        "\n",
        "    b[\"bin_edges\"].append(bin_all) \n",
        "    b[\"class\"].append(class_)\n",
        "      \n",
        "  training_data = np.array(b[\"bin_edges\"])\n",
        "  labels = np.array(b[\"class\"])\n",
        "\n",
        "  return(training_data, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJpsgIPE8S0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quantile Sketch Array\n",
        "def binning_norm(data, b):\n",
        "  \"\"\"takes in a list of values (data) and number of bins b and bins the values of the feature according \n",
        "  to the bin edges produced by the KBinsDiscretizer function, and returns the normalized value for each bin\"\"\"\n",
        "  model = KBinsDiscretizer(n_bins=b, encode='ordinal', strategy='uniform')\n",
        "\n",
        "  model.fit(data.reshape(-1,1))\n",
        "\n",
        "  bin_edges = model.bin_edges_[0]\n",
        "  bin_values = []\n",
        "  bin_edges = np.delete(bin_edges, 0)\n",
        "  old_ran = -10\n",
        "  #counting number of values in each bin\n",
        "  for x,ran in enumerate(bin_edges):\n",
        "    if x == len(bin_edges)-1:\n",
        "      num = sum(1 for x in data if x <= ran and x >= old_ran)\n",
        "    else:\n",
        "      num = sum(1 for x in data if x < ran and x >= old_ran)\n",
        "    old_ran = ran\n",
        "    bin_values.append(num)\n",
        "  bin_values = [y/len(data) for y in bin_values] #normalizing the count\n",
        "  return(bin_values)\n",
        "    \n",
        "def binning_normalized(features_list, data, y, class_, bins):\n",
        "  \"\"\"given a list of features, divides the values into two lists accrording to the class,\n",
        "  then scales the values and applies binning norm function, then returns the fixed-size arrays of the data\"\"\"\n",
        "  bin_edge_pos = []\n",
        "  bin_edge_neg = []\n",
        "  b = {\"bin_edges\":[], \"class\": []}\n",
        "  \n",
        "  for feature in features_list:\n",
        "\n",
        "    data_feature = list(data[feature])\n",
        "    x_f_pos = [z for x,z in enumerate(data_feature) if y[x] ==1]\n",
        "    x_f_neg = [z for x,z in enumerate(data_feature) if y[x] ==0]\n",
        "\n",
        "    x_f_pos = np.array(x_f_pos).reshape(-1,1)\n",
        "    x_f_neg = np.array(x_f_neg).reshape(-1,1)\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "    scaler = scaler.fit(x_f_pos)\n",
        "    x_f_pos = scaler.transform(x_f_pos)\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(-10, 10))\n",
        "    scaler = scaler.fit(x_f_neg)\n",
        "    x_f_neg = scaler.transform(x_f_neg)\n",
        "\n",
        "    bin_all = []\n",
        "    bin_all.extend(binning_norm(x_f_pos, bins))\n",
        "    bin_all.extend(binning_norm(x_f_neg, bins))\n",
        "\n",
        "    b[\"bin_edges\"].append(bin_all) \n",
        "    b[\"class\"].append(class_)\n",
        "      \n",
        "  training_data = np.array(b[\"bin_edges\"])\n",
        "  labels = np.array(b[\"class\"])\n",
        "\n",
        "  return(training_data, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jwkAIvU8aNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the datasets from the drive\n",
        "files = glob.glob('/content/drive/My Drive/Auto-AI-2019-20/New cleaned classification dataset/*.csv')   # create the list of file\n",
        "X_ls, Y_ls = get_data(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwAKm-k0-EI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6a33324e-2e21-4096-9737-943c8c42dbd6"
      },
      "source": [
        "# with open('new_x_ls.pickle', 'wb') as handle:\n",
        "#     pickle.dump(new_x_ls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('new_y_ls.pickle', 'wb') as handle:\n",
        "#     pickle.dump(new_y_ls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('new_x_ls.pickle') \n",
        "# files.download('new_y_ls.pickle') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_375bac4e-6555-4359-9b19-c4e49548db38\", \"new_x_ls.pickle\", 80007428)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_305680b6-c343-4876-b761-ac39025d7a8d\", \"new_y_ls.pickle\", 2350020)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrnP7w1lEVEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/new_x_ls.pickle', 'rb') as handle:\n",
        "  new_x_ls = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/new_y_ls.pickle', 'rb') as handle:\n",
        "  new_y_ls = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrcMyKwS8dxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 1\n",
        "pos_list = []\n",
        "neg_list = []\n",
        "\n",
        "for dataset, label in zip(new_x_ls, new_y_ls):\n",
        "  print(\"Training dataset \" + str(i) + \"...\")\n",
        "\n",
        "  scaled_dataset = scale(dataset)\n",
        "\n",
        "  features = [[col] for col in scaled_dataset.columns]\n",
        "\n",
        "  count_0 = len([1 for y in label if y == 0])\n",
        "  count_1 = len([1 for y in label if y == 1])\n",
        "  min_count = min(count_0,count_1)\n",
        "  if min_count/len(label) < 0.4: \n",
        "    positive_samples, negative_samples = feature_trans(label, scaled_dataset, features, 0.01,\"freq\",\"sm\")\n",
        "  else:\n",
        "    positive_samples, negative_samples = feature_trans(label, scaled_dataset, features, 0.01,\"freq\",\"no\")\n",
        "\n",
        "  pos_list.append(positive_samples)\n",
        "  neg_list.append(negative_samples)\n",
        "\n",
        "  i +=1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJdJFzxEIKdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "733bff3c-3fc3-47d9-f9d5-2c90bd0d2e04"
      },
      "source": [
        "import pickle\n",
        "with open('pos_rf_freq.pickle', 'wb') as handle:\n",
        "    pickle.dump(pos_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('neg_rf_freq.pickle', 'wb') as handle:\n",
        "    pickle.dump(neg_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('pos_rf_freq.pickle') \n",
        "files.download('neg_rf_freq.pickle') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_986379e9-c6c6-4ea1-8d6d-62de76930412\", \"pos_rf_freq.pickle\", 2002)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f3ce3630-f706-489c-b643-682f433bd348\", \"neg_rf_freq.pickle\", 13563)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkkIbW7jRTTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/pos_rf_freq.pickle', 'rb') as handle:\n",
        "  pos_list = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/neg_rf_freq.pickle', 'rb') as handle:\n",
        "  neg_list = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0_TpTzJNVyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f2fa5935-5746-4624-a68f-6672797aa569"
      },
      "source": [
        "training_data = []\n",
        "training_labels = []\n",
        "\n",
        "for i, (dataset, label) in enumerate(zip(new_x_ls,new_y_ls)):\n",
        "  if len(pos_list[i]) == 0:\n",
        "      neg_training, neg_labels = binning_normalized(neg_list[i], dataset, label, 0, 200)\n",
        "      training_data.extend(neg_training)\n",
        "      training_labels.extend(neg_labels)\n",
        "  elif len(neg_list[i]) == 0:\n",
        "    pos_training, pos_labels = binning_normalized(pos_list[i], dataset, label, 1, 200)\n",
        "    training_data.extend(pos_training)\n",
        "    training_labels.extend(pos_labels)\n",
        "  else:\n",
        "    pos_training, pos_labels = binning_normalized(pos_list[i], dataset, label, 1, 200)\n",
        "    neg_training, neg_labels = binning_normalized(neg_list[i], dataset, label, 0, 200)\n",
        "    training_data.extend(pos_training)\n",
        "    training_data.extend(neg_training) \n",
        "    training_labels.extend(pos_labels)\n",
        "    training_labels.extend(neg_labels) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_discretization.py:163: UserWarning:\n",
            "\n",
            "Feature 0 is constant and will be replaced with 0.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVOv21o6NXVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "00568642-c4b0-484a-f57b-aa63ffc40cce"
      },
      "source": [
        "import pickle\n",
        "with open('train_rf_freq_qsa.pickle', 'wb') as handle:\n",
        "    pickle.dump(training, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('label_rf_freq_qsa.pickle', 'wb') as handle:\n",
        "    pickle.dump(label, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('train_rf_freq_qsa.pickle') \n",
        "files.download('label_rf_freq_qsa.pickle') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5ef85e6b-9bee-44d4-9dba-06b8d4ee3c38\", \"train_rf_freq_qsa.pickle\", 6278709)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_99f6c938-85dc-4b8c-8b15-430c1b89913e\", \"label_rf_freq_qsa.pickle\", 36946)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tOBOIUAXiHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/train_rf_freq_qsa.pickle', 'rb') as handle:\n",
        "  training = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/mira/label_rf_freq_qsa.pickle', 'rb') as handle:\n",
        "  label = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adRo7WgTXpB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del training[594]\n",
        "del label[594]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE5FfvczduxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = []\n",
        "training_labels = []\n",
        "\n",
        "for i, (dataset, label) in enumerate(zip(new_x_ls,new_y_ls)):\n",
        "  if len(pos_list[i]) == 0:\n",
        "      neg_training, neg_labels = binning_quantile(neg_list[i], dataset, label, 0, 200)\n",
        "      training_data.extend(neg_training)\n",
        "      training_labels.extend(neg_labels)\n",
        "  elif len(neg_list[i]) == 0:\n",
        "    pos_training, pos_labels = binning_quantile(pos_list[i], dataset, label, 1, 200)\n",
        "    training_data.extend(pos_training)\n",
        "    training_labels.extend(pos_labels)\n",
        "  else:\n",
        "    pos_training, pos_labels = binning_quantile(pos_list[i], dataset, label, 1, 200)\n",
        "    neg_training, neg_labels = binning_quantile(neg_list[i], dataset, label, 0, 200)\n",
        "    training_data.extend(pos_training)\n",
        "    training_data.extend(neg_training) \n",
        "    training_labels.extend(pos_labels)\n",
        "    training_labels.extend(neg_labels) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSndNi4iGdkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e63001d6-46f6-4aec-981c-9dbc1a8cf558"
      },
      "source": [
        "with open('train_rf_freq_perc.pickle', 'wb') as handle:\n",
        "    pickle.dump(training_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('label_rf_freq_perc.pickle', 'wb') as handle:\n",
        "    pickle.dump(training_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('train_rf_freq_perc.pickle') \n",
        "files.download('label_rf_freq_perc.pickle') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_644ad307-0bc1-4d45-8ef6-c67bfbe22c00\", \"train_rf_freq_perc.pickle\", 6274913)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5dfc945b-e935-4556-852b-943e59e85abc\", \"label_rf_freq_perc.pickle\", 36965)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}