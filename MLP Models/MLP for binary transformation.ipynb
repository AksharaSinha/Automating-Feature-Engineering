{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BINARY Log Reg ClASSIFICATION MLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOs-aKzxn-ub",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm3qZsGKn4_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "78c04e82-b520-4d64-9d2d-db8173a53364"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import pickle\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6x2tjbryMw",
        "colab_type": "text"
      },
      "source": [
        "# **Random Forest threshold 0.01**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CjJJnduoDjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/train_add005.pickle', 'rb') as handle:\n",
        "    training_dataa = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/label_add005.pickle', 'rb') as handle:\n",
        "    training_labelss = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK9Id8eAoZLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c48485be-fb7d-4881-a1cf-988d44bd9b82"
      },
      "source": [
        "# Using SMOTE \n",
        "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(training_dataa, training_labelss)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0, test_size=0.1)\n",
        "#x_train, x_test, y_train, y_test = train_test_split(training_dataa, training_labelss, random_state=0, test_size=0.1)\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)\n",
        "\n",
        "\n",
        "#using class weights to balance the data\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# convert list of labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "\n",
        "\n",
        "#Reshaping\n",
        "input_dim = X_train.shape[1]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "# Here's an MLP \n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(128, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(128))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('logclass-bin-add05.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "print(\"Training...\")\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [es,mc],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 1.1545 - accuracy: 0.6632\n",
            "Epoch 00001: val_loss improved from inf to 0.51072, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.1462 - accuracy: 0.6631 - val_loss: 0.5107 - val_accuracy: 0.7610\n",
            "Epoch 2/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.5493 - accuracy: 0.7256\n",
            "Epoch 00002: val_loss improved from 0.51072 to 0.48298, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5490 - accuracy: 0.7258 - val_loss: 0.4830 - val_accuracy: 0.7686\n",
            "Epoch 3/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7452\n",
            "Epoch 00003: val_loss improved from 0.48298 to 0.48034, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7450 - val_loss: 0.4803 - val_accuracy: 0.7711\n",
            "Epoch 4/250\n",
            "271/278 [============================>.] - ETA: 0s - loss: 0.5086 - accuracy: 0.7591\n",
            "Epoch 00004: val_loss improved from 0.48034 to 0.47324, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.7596 - val_loss: 0.4732 - val_accuracy: 0.7887\n",
            "Epoch 5/250\n",
            "276/278 [============================>.] - ETA: 0s - loss: 0.4985 - accuracy: 0.7675\n",
            "Epoch 00005: val_loss improved from 0.47324 to 0.46192, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7676 - val_loss: 0.4619 - val_accuracy: 0.7925\n",
            "Epoch 6/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.7719\n",
            "Epoch 00006: val_loss improved from 0.46192 to 0.45280, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7720 - val_loss: 0.4528 - val_accuracy: 0.7887\n",
            "Epoch 7/250\n",
            "261/278 [===========================>..] - ETA: 0s - loss: 0.4862 - accuracy: 0.7759\n",
            "Epoch 00007: val_loss did not improve from 0.45280\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7765 - val_loss: 0.4530 - val_accuracy: 0.7765\n",
            "Epoch 8/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.4765 - accuracy: 0.7793\n",
            "Epoch 00008: val_loss improved from 0.45280 to 0.44120, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.7789 - val_loss: 0.4412 - val_accuracy: 0.7993\n",
            "Epoch 9/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.7849\n",
            "Epoch 00009: val_loss did not improve from 0.44120\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.7845 - val_loss: 0.4478 - val_accuracy: 0.7982\n",
            "Epoch 10/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.4643 - accuracy: 0.7896\n",
            "Epoch 00010: val_loss improved from 0.44120 to 0.43271, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4643 - accuracy: 0.7895 - val_loss: 0.4327 - val_accuracy: 0.8038\n",
            "Epoch 11/250\n",
            "276/278 [============================>.] - ETA: 0s - loss: 0.4578 - accuracy: 0.7917\n",
            "Epoch 00011: val_loss improved from 0.43271 to 0.42907, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.7921 - val_loss: 0.4291 - val_accuracy: 0.8101\n",
            "Epoch 12/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.7941\n",
            "Epoch 00012: val_loss improved from 0.42907 to 0.42615, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.7938 - val_loss: 0.4262 - val_accuracy: 0.8103\n",
            "Epoch 13/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.4546 - accuracy: 0.7952\n",
            "Epoch 00013: val_loss did not improve from 0.42615\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.7958 - val_loss: 0.4262 - val_accuracy: 0.8076\n",
            "Epoch 14/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.7943\n",
            "Epoch 00014: val_loss improved from 0.42615 to 0.42057, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.7938 - val_loss: 0.4206 - val_accuracy: 0.8139\n",
            "Epoch 15/250\n",
            "257/278 [==========================>...] - ETA: 0s - loss: 0.4464 - accuracy: 0.7975\n",
            "Epoch 00015: val_loss improved from 0.42057 to 0.41624, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.7988 - val_loss: 0.4162 - val_accuracy: 0.8178\n",
            "Epoch 16/250\n",
            "271/278 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.7992\n",
            "Epoch 00016: val_loss did not improve from 0.41624\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.7998 - val_loss: 0.4176 - val_accuracy: 0.8189\n",
            "Epoch 17/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.4411 - accuracy: 0.8031\n",
            "Epoch 00017: val_loss did not improve from 0.41624\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.8031 - val_loss: 0.4179 - val_accuracy: 0.8094\n",
            "Epoch 18/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8035\n",
            "Epoch 00018: val_loss improved from 0.41624 to 0.41437, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.8034 - val_loss: 0.4144 - val_accuracy: 0.8135\n",
            "Epoch 19/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.4353 - accuracy: 0.8027\n",
            "Epoch 00019: val_loss improved from 0.41437 to 0.40988, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.8033 - val_loss: 0.4099 - val_accuracy: 0.8162\n",
            "Epoch 20/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.4352 - accuracy: 0.8052\n",
            "Epoch 00020: val_loss did not improve from 0.40988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8059 - val_loss: 0.4174 - val_accuracy: 0.8119\n",
            "Epoch 21/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8052\n",
            "Epoch 00021: val_loss improved from 0.40988 to 0.40882, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.8047 - val_loss: 0.4088 - val_accuracy: 0.8209\n",
            "Epoch 22/250\n",
            "270/278 [============================>.] - ETA: 0s - loss: 0.4291 - accuracy: 0.8060\n",
            "Epoch 00022: val_loss improved from 0.40882 to 0.40430, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4291 - accuracy: 0.8064 - val_loss: 0.4043 - val_accuracy: 0.8261\n",
            "Epoch 23/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.8054\n",
            "Epoch 00023: val_loss improved from 0.40430 to 0.40261, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.8064 - val_loss: 0.4026 - val_accuracy: 0.8241\n",
            "Epoch 24/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.8076\n",
            "Epoch 00024: val_loss did not improve from 0.40261\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.8077 - val_loss: 0.4081 - val_accuracy: 0.8155\n",
            "Epoch 25/250\n",
            "271/278 [============================>.] - ETA: 0s - loss: 0.4258 - accuracy: 0.8094\n",
            "Epoch 00025: val_loss did not improve from 0.40261\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8092 - val_loss: 0.4098 - val_accuracy: 0.8144\n",
            "Epoch 26/250\n",
            "263/278 [===========================>..] - ETA: 0s - loss: 0.4259 - accuracy: 0.8106\n",
            "Epoch 00026: val_loss improved from 0.40261 to 0.40185, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8105 - val_loss: 0.4019 - val_accuracy: 0.8283\n",
            "Epoch 27/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.4229 - accuracy: 0.8128\n",
            "Epoch 00027: val_loss did not improve from 0.40185\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8127 - val_loss: 0.4053 - val_accuracy: 0.8225\n",
            "Epoch 28/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.4192 - accuracy: 0.8143\n",
            "Epoch 00028: val_loss improved from 0.40185 to 0.39934, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8144 - val_loss: 0.3993 - val_accuracy: 0.8256\n",
            "Epoch 29/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.8141\n",
            "Epoch 00029: val_loss improved from 0.39934 to 0.39925, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4181 - accuracy: 0.8139 - val_loss: 0.3993 - val_accuracy: 0.8223\n",
            "Epoch 30/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8140\n",
            "Epoch 00030: val_loss did not improve from 0.39925\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8140 - val_loss: 0.4045 - val_accuracy: 0.8164\n",
            "Epoch 31/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8148\n",
            "Epoch 00031: val_loss improved from 0.39925 to 0.39525, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4177 - accuracy: 0.8153 - val_loss: 0.3952 - val_accuracy: 0.8274\n",
            "Epoch 32/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.4143 - accuracy: 0.8148\n",
            "Epoch 00032: val_loss did not improve from 0.39525\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8141 - val_loss: 0.3959 - val_accuracy: 0.8295\n",
            "Epoch 33/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8160\n",
            "Epoch 00033: val_loss did not improve from 0.39525\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4153 - accuracy: 0.8157 - val_loss: 0.3990 - val_accuracy: 0.8265\n",
            "Epoch 34/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.4120 - accuracy: 0.8191\n",
            "Epoch 00034: val_loss improved from 0.39525 to 0.39423, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4119 - accuracy: 0.8187 - val_loss: 0.3942 - val_accuracy: 0.8306\n",
            "Epoch 35/250\n",
            "261/278 [===========================>..] - ETA: 0s - loss: 0.4095 - accuracy: 0.8184\n",
            "Epoch 00035: val_loss improved from 0.39423 to 0.39006, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8182 - val_loss: 0.3901 - val_accuracy: 0.8274\n",
            "Epoch 36/250\n",
            "263/278 [===========================>..] - ETA: 0s - loss: 0.4121 - accuracy: 0.8202\n",
            "Epoch 00036: val_loss did not improve from 0.39006\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8201 - val_loss: 0.3924 - val_accuracy: 0.8306\n",
            "Epoch 37/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.4121 - accuracy: 0.8185\n",
            "Epoch 00037: val_loss did not improve from 0.39006\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4090 - accuracy: 0.8200 - val_loss: 0.3955 - val_accuracy: 0.8279\n",
            "Epoch 38/250\n",
            "261/278 [===========================>..] - ETA: 0s - loss: 0.4139 - accuracy: 0.8183\n",
            "Epoch 00038: val_loss did not improve from 0.39006\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8189 - val_loss: 0.3937 - val_accuracy: 0.8272\n",
            "Epoch 39/250\n",
            "261/278 [===========================>..] - ETA: 0s - loss: 0.4121 - accuracy: 0.8187\n",
            "Epoch 00039: val_loss improved from 0.39006 to 0.38918, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8187 - val_loss: 0.3892 - val_accuracy: 0.8297\n",
            "Epoch 40/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.4084 - accuracy: 0.8220\n",
            "Epoch 00040: val_loss improved from 0.38918 to 0.38844, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4087 - accuracy: 0.8221 - val_loss: 0.3884 - val_accuracy: 0.8367\n",
            "Epoch 41/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.4078 - accuracy: 0.8191\n",
            "Epoch 00041: val_loss improved from 0.38844 to 0.38531, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4071 - accuracy: 0.8191 - val_loss: 0.3853 - val_accuracy: 0.8317\n",
            "Epoch 42/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8218\n",
            "Epoch 00042: val_loss did not improve from 0.38531\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4047 - accuracy: 0.8218 - val_loss: 0.3870 - val_accuracy: 0.8333\n",
            "Epoch 43/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.4052 - accuracy: 0.8232\n",
            "Epoch 00043: val_loss did not improve from 0.38531\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8229 - val_loss: 0.3875 - val_accuracy: 0.8281\n",
            "Epoch 44/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8243\n",
            "Epoch 00044: val_loss did not improve from 0.38531\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4040 - accuracy: 0.8245 - val_loss: 0.3929 - val_accuracy: 0.8315\n",
            "Epoch 45/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.4031 - accuracy: 0.8230\n",
            "Epoch 00045: val_loss did not improve from 0.38531\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8232 - val_loss: 0.3867 - val_accuracy: 0.8306\n",
            "Epoch 46/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.4006 - accuracy: 0.8237\n",
            "Epoch 00046: val_loss improved from 0.38531 to 0.38397, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8237 - val_loss: 0.3840 - val_accuracy: 0.8308\n",
            "Epoch 47/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3996 - accuracy: 0.8234\n",
            "Epoch 00047: val_loss did not improve from 0.38397\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8237 - val_loss: 0.3899 - val_accuracy: 0.8272\n",
            "Epoch 48/250\n",
            "276/278 [============================>.] - ETA: 0s - loss: 0.4019 - accuracy: 0.8242\n",
            "Epoch 00048: val_loss improved from 0.38397 to 0.38357, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8243 - val_loss: 0.3836 - val_accuracy: 0.8369\n",
            "Epoch 49/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.8247\n",
            "Epoch 00049: val_loss improved from 0.38357 to 0.38258, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8256 - val_loss: 0.3826 - val_accuracy: 0.8308\n",
            "Epoch 50/250\n",
            "257/278 [==========================>...] - ETA: 0s - loss: 0.3984 - accuracy: 0.8265\n",
            "Epoch 00050: val_loss improved from 0.38258 to 0.38061, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8270 - val_loss: 0.3806 - val_accuracy: 0.8324\n",
            "Epoch 51/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.3966 - accuracy: 0.8285\n",
            "Epoch 00051: val_loss did not improve from 0.38061\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8277 - val_loss: 0.3829 - val_accuracy: 0.8371\n",
            "Epoch 52/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8269\n",
            "Epoch 00052: val_loss improved from 0.38061 to 0.37984, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3977 - accuracy: 0.8269 - val_loss: 0.3798 - val_accuracy: 0.8371\n",
            "Epoch 53/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8266\n",
            "Epoch 00053: val_loss did not improve from 0.37984\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8265 - val_loss: 0.3828 - val_accuracy: 0.8369\n",
            "Epoch 54/250\n",
            "276/278 [============================>.] - ETA: 0s - loss: 0.3943 - accuracy: 0.8291\n",
            "Epoch 00054: val_loss did not improve from 0.37984\n",
            "278/278 [==============================] - 1s 4ms/step - loss: 0.3942 - accuracy: 0.8291 - val_loss: 0.3837 - val_accuracy: 0.8299\n",
            "Epoch 55/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3918 - accuracy: 0.8301\n",
            "Epoch 00055: val_loss improved from 0.37984 to 0.37459, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.3746 - val_accuracy: 0.8401\n",
            "Epoch 56/250\n",
            "260/278 [===========================>..] - ETA: 0s - loss: 0.3973 - accuracy: 0.8276\n",
            "Epoch 00056: val_loss did not improve from 0.37459\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8284 - val_loss: 0.3868 - val_accuracy: 0.8322\n",
            "Epoch 57/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.3924 - accuracy: 0.8280\n",
            "Epoch 00057: val_loss did not improve from 0.37459\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8276 - val_loss: 0.3801 - val_accuracy: 0.8376\n",
            "Epoch 58/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3919 - accuracy: 0.8291\n",
            "Epoch 00058: val_loss did not improve from 0.37459\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8297 - val_loss: 0.3760 - val_accuracy: 0.8392\n",
            "Epoch 59/250\n",
            "262/278 [===========================>..] - ETA: 0s - loss: 0.3913 - accuracy: 0.8296\n",
            "Epoch 00059: val_loss did not improve from 0.37459\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3916 - accuracy: 0.8303 - val_loss: 0.3757 - val_accuracy: 0.8367\n",
            "Epoch 60/250\n",
            "263/278 [===========================>..] - ETA: 0s - loss: 0.3896 - accuracy: 0.8312\n",
            "Epoch 00060: val_loss improved from 0.37459 to 0.37194, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3893 - accuracy: 0.8317 - val_loss: 0.3719 - val_accuracy: 0.8421\n",
            "Epoch 61/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8322\n",
            "Epoch 00061: val_loss did not improve from 0.37194\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3892 - accuracy: 0.8323 - val_loss: 0.3810 - val_accuracy: 0.8378\n",
            "Epoch 62/250\n",
            "271/278 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8358\n",
            "Epoch 00062: val_loss did not improve from 0.37194\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.8355 - val_loss: 0.3744 - val_accuracy: 0.8407\n",
            "Epoch 63/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.3833 - accuracy: 0.8345\n",
            "Epoch 00063: val_loss did not improve from 0.37194\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3839 - accuracy: 0.8339 - val_loss: 0.3786 - val_accuracy: 0.8394\n",
            "Epoch 64/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3868 - accuracy: 0.8340\n",
            "Epoch 00064: val_loss did not improve from 0.37194\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8336 - val_loss: 0.3762 - val_accuracy: 0.8407\n",
            "Epoch 65/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.3832 - accuracy: 0.8358\n",
            "Epoch 00065: val_loss did not improve from 0.37194\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8359 - val_loss: 0.3744 - val_accuracy: 0.8407\n",
            "Epoch 66/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8331\n",
            "Epoch 00066: val_loss improved from 0.37194 to 0.36945, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3875 - accuracy: 0.8329 - val_loss: 0.3694 - val_accuracy: 0.8464\n",
            "Epoch 67/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.3888 - accuracy: 0.8306\n",
            "Epoch 00067: val_loss did not improve from 0.36945\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3896 - accuracy: 0.8307 - val_loss: 0.3791 - val_accuracy: 0.8333\n",
            "Epoch 68/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8325\n",
            "Epoch 00068: val_loss improved from 0.36945 to 0.36782, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3871 - accuracy: 0.8332 - val_loss: 0.3678 - val_accuracy: 0.8430\n",
            "Epoch 69/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8347\n",
            "Epoch 00069: val_loss improved from 0.36782 to 0.36741, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3821 - accuracy: 0.8340 - val_loss: 0.3674 - val_accuracy: 0.8428\n",
            "Epoch 70/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.3812 - accuracy: 0.8360\n",
            "Epoch 00070: val_loss did not improve from 0.36741\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8356 - val_loss: 0.3850 - val_accuracy: 0.8301\n",
            "Epoch 71/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8351\n",
            "Epoch 00071: val_loss did not improve from 0.36741\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3808 - accuracy: 0.8353 - val_loss: 0.3712 - val_accuracy: 0.8414\n",
            "Epoch 72/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.3819 - accuracy: 0.8363\n",
            "Epoch 00072: val_loss did not improve from 0.36741\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3805 - accuracy: 0.8376 - val_loss: 0.3727 - val_accuracy: 0.8423\n",
            "Epoch 73/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8364\n",
            "Epoch 00073: val_loss improved from 0.36741 to 0.36377, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3817 - accuracy: 0.8363 - val_loss: 0.3638 - val_accuracy: 0.8475\n",
            "Epoch 74/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8369\n",
            "Epoch 00074: val_loss did not improve from 0.36377\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3786 - accuracy: 0.8367 - val_loss: 0.3649 - val_accuracy: 0.8464\n",
            "Epoch 75/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.3841 - accuracy: 0.8362\n",
            "Epoch 00075: val_loss did not improve from 0.36377\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8362 - val_loss: 0.3674 - val_accuracy: 0.8484\n",
            "Epoch 76/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3759 - accuracy: 0.8389\n",
            "Epoch 00076: val_loss did not improve from 0.36377\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8392 - val_loss: 0.3641 - val_accuracy: 0.8524\n",
            "Epoch 77/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.3760 - accuracy: 0.8403\n",
            "Epoch 00077: val_loss did not improve from 0.36377\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8403 - val_loss: 0.3726 - val_accuracy: 0.8416\n",
            "Epoch 78/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.3768 - accuracy: 0.8403\n",
            "Epoch 00078: val_loss did not improve from 0.36377\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8411 - val_loss: 0.3640 - val_accuracy: 0.8430\n",
            "Epoch 79/250\n",
            "263/278 [===========================>..] - ETA: 0s - loss: 0.3822 - accuracy: 0.8377\n",
            "Epoch 00079: val_loss improved from 0.36377 to 0.36114, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8392 - val_loss: 0.3611 - val_accuracy: 0.8486\n",
            "Epoch 80/250\n",
            "276/278 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8396\n",
            "Epoch 00080: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8397 - val_loss: 0.3627 - val_accuracy: 0.8459\n",
            "Epoch 81/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.8421\n",
            "Epoch 00081: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8420 - val_loss: 0.3619 - val_accuracy: 0.8527\n",
            "Epoch 82/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8388\n",
            "Epoch 00082: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3802 - accuracy: 0.8388 - val_loss: 0.3634 - val_accuracy: 0.8488\n",
            "Epoch 83/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8373\n",
            "Epoch 00083: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.8370 - val_loss: 0.3648 - val_accuracy: 0.8488\n",
            "Epoch 84/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8393\n",
            "Epoch 00084: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8393 - val_loss: 0.3668 - val_accuracy: 0.8459\n",
            "Epoch 85/250\n",
            "262/278 [===========================>..] - ETA: 0s - loss: 0.3788 - accuracy: 0.8390\n",
            "Epoch 00085: val_loss did not improve from 0.36114\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8390 - val_loss: 0.3660 - val_accuracy: 0.8464\n",
            "Epoch 86/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3713 - accuracy: 0.8421\n",
            "Epoch 00086: val_loss improved from 0.36114 to 0.36098, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3707 - accuracy: 0.8424 - val_loss: 0.3610 - val_accuracy: 0.8491\n",
            "Epoch 87/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8440\n",
            "Epoch 00087: val_loss did not improve from 0.36098\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3723 - accuracy: 0.8441 - val_loss: 0.3619 - val_accuracy: 0.8500\n",
            "Epoch 88/250\n",
            "262/278 [===========================>..] - ETA: 0s - loss: 0.3754 - accuracy: 0.8429\n",
            "Epoch 00088: val_loss improved from 0.36098 to 0.35722, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8437 - val_loss: 0.3572 - val_accuracy: 0.8542\n",
            "Epoch 89/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.3671 - accuracy: 0.8462\n",
            "Epoch 00089: val_loss did not improve from 0.35722\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8456 - val_loss: 0.3632 - val_accuracy: 0.8506\n",
            "Epoch 90/250\n",
            "263/278 [===========================>..] - ETA: 0s - loss: 0.3729 - accuracy: 0.8418\n",
            "Epoch 00090: val_loss did not improve from 0.35722\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.8429 - val_loss: 0.3712 - val_accuracy: 0.8448\n",
            "Epoch 91/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3697 - accuracy: 0.8431\n",
            "Epoch 00091: val_loss improved from 0.35722 to 0.35662, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8425 - val_loss: 0.3566 - val_accuracy: 0.8493\n",
            "Epoch 92/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8406\n",
            "Epoch 00092: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8406 - val_loss: 0.3634 - val_accuracy: 0.8493\n",
            "Epoch 93/250\n",
            "275/278 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.8441\n",
            "Epoch 00093: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8438 - val_loss: 0.3568 - val_accuracy: 0.8524\n",
            "Epoch 94/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.3706 - accuracy: 0.8424\n",
            "Epoch 00094: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8426 - val_loss: 0.3635 - val_accuracy: 0.8504\n",
            "Epoch 95/250\n",
            "259/278 [==========================>...] - ETA: 0s - loss: 0.3686 - accuracy: 0.8442\n",
            "Epoch 00095: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3690 - accuracy: 0.8439 - val_loss: 0.3575 - val_accuracy: 0.8482\n",
            "Epoch 96/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.3683 - accuracy: 0.8456\n",
            "Epoch 00096: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8456 - val_loss: 0.3588 - val_accuracy: 0.8547\n",
            "Epoch 97/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8469\n",
            "Epoch 00097: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3652 - accuracy: 0.8473 - val_loss: 0.3605 - val_accuracy: 0.8511\n",
            "Epoch 98/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3697 - accuracy: 0.8447\n",
            "Epoch 00098: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8446 - val_loss: 0.3593 - val_accuracy: 0.8495\n",
            "Epoch 99/250\n",
            "264/278 [===========================>..] - ETA: 0s - loss: 0.3641 - accuracy: 0.8466\n",
            "Epoch 00099: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8472 - val_loss: 0.3597 - val_accuracy: 0.8520\n",
            "Epoch 100/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8432\n",
            "Epoch 00100: val_loss did not improve from 0.35662\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8435 - val_loss: 0.3608 - val_accuracy: 0.8506\n",
            "Epoch 101/250\n",
            "262/278 [===========================>..] - ETA: 0s - loss: 0.3654 - accuracy: 0.8470\n",
            "Epoch 00101: val_loss improved from 0.35662 to 0.35406, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8473 - val_loss: 0.3541 - val_accuracy: 0.8549\n",
            "Epoch 102/250\n",
            "261/278 [===========================>..] - ETA: 0s - loss: 0.3677 - accuracy: 0.8433\n",
            "Epoch 00102: val_loss did not improve from 0.35406\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8438 - val_loss: 0.3653 - val_accuracy: 0.8484\n",
            "Epoch 103/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.3675 - accuracy: 0.8430\n",
            "Epoch 00103: val_loss did not improve from 0.35406\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3669 - accuracy: 0.8437 - val_loss: 0.3574 - val_accuracy: 0.8549\n",
            "Epoch 104/250\n",
            "265/278 [===========================>..] - ETA: 0s - loss: 0.3653 - accuracy: 0.8435\n",
            "Epoch 00104: val_loss did not improve from 0.35406\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3652 - accuracy: 0.8435 - val_loss: 0.3541 - val_accuracy: 0.8497\n",
            "Epoch 105/250\n",
            "268/278 [===========================>..] - ETA: 0s - loss: 0.3651 - accuracy: 0.8478\n",
            "Epoch 00105: val_loss did not improve from 0.35406\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3667 - accuracy: 0.8470 - val_loss: 0.3630 - val_accuracy: 0.8504\n",
            "Epoch 106/250\n",
            "260/278 [===========================>..] - ETA: 0s - loss: 0.3622 - accuracy: 0.8466\n",
            "Epoch 00106: val_loss improved from 0.35406 to 0.35137, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8478 - val_loss: 0.3514 - val_accuracy: 0.8511\n",
            "Epoch 107/250\n",
            "272/278 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.8486\n",
            "Epoch 00107: val_loss did not improve from 0.35137\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8482 - val_loss: 0.3526 - val_accuracy: 0.8563\n",
            "Epoch 108/250\n",
            "274/278 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.8481\n",
            "Epoch 00108: val_loss improved from 0.35137 to 0.34988, saving model to logclass-bin-add05.h5\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8484 - val_loss: 0.3499 - val_accuracy: 0.8545\n",
            "Epoch 109/250\n",
            "273/278 [============================>.] - ETA: 0s - loss: 0.3643 - accuracy: 0.8471\n",
            "Epoch 00109: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8471 - val_loss: 0.3618 - val_accuracy: 0.8520\n",
            "Epoch 110/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8470\n",
            "Epoch 00110: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3631 - accuracy: 0.8470 - val_loss: 0.3548 - val_accuracy: 0.8540\n",
            "Epoch 111/250\n",
            "267/278 [===========================>..] - ETA: 0s - loss: 0.3602 - accuracy: 0.8481\n",
            "Epoch 00111: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8474 - val_loss: 0.3595 - val_accuracy: 0.8491\n",
            "Epoch 112/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.3608 - accuracy: 0.8477\n",
            "Epoch 00112: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8483 - val_loss: 0.3552 - val_accuracy: 0.8506\n",
            "Epoch 113/250\n",
            "266/278 [===========================>..] - ETA: 0s - loss: 0.3648 - accuracy: 0.8463\n",
            "Epoch 00113: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3502 - val_accuracy: 0.8592\n",
            "Epoch 114/250\n",
            "269/278 [============================>.] - ETA: 0s - loss: 0.3608 - accuracy: 0.8498\n",
            "Epoch 00114: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8497 - val_loss: 0.3529 - val_accuracy: 0.8527\n",
            "Epoch 115/250\n",
            "259/278 [==========================>...] - ETA: 0s - loss: 0.3633 - accuracy: 0.8473\n",
            "Epoch 00115: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8465 - val_loss: 0.3547 - val_accuracy: 0.8551\n",
            "Epoch 116/250\n",
            "277/278 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.8504\n",
            "Epoch 00116: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8504 - val_loss: 0.3580 - val_accuracy: 0.8495\n",
            "Epoch 117/250\n",
            "270/278 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8502\n",
            "Epoch 00117: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3548 - val_accuracy: 0.8565\n",
            "Epoch 118/250\n",
            "278/278 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8477\n",
            "Epoch 00118: val_loss did not improve from 0.34988\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3590 - accuracy: 0.8477 - val_loss: 0.3591 - val_accuracy: 0.8473\n",
            "Epoch 00118: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffNdSQ-7pjhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ac550cc8-9dc6-4429-f0c4-b3215bc0f0c4"
      },
      "source": [
        "sqr_model = tf.python.keras.models.load_model('logclass-bin-add05.h5')\n",
        "adam_predictions = sqr_model.predict(X_test, verbose=1)\n",
        "# prediction and clasification report\n",
        "y_true, y_pred = [],[]\n",
        "#classes = le.classes_\n",
        "for idx, prediction in enumerate(adam_predictions): \n",
        "    y_true.append([np.argmax(y_test[idx])])\n",
        "    y_pred.append([np.argmax(prediction)])\n",
        "    \n",
        "print(sklearn.metrics.classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 0s 998us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83      1003\n",
            "           1       0.94      0.79      0.86      1464\n",
            "\n",
            "    accuracy                           0.85      2467\n",
            "   macro avg       0.85      0.86      0.85      2467\n",
            "weighted avg       0.86      0.85      0.85      2467\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq0VQ4PaQ5gE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "06697512-6065-4da4-b2c5-79677c65d6f8"
      },
      "source": [
        "files.download('logclass-bin-add05.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3b970552-533e-45a4-8357-c4f98eec6459\", \"logclass-bin-add05.h5\", 753976)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRuBSx0PpqaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/train_minus005.pickle', 'rb') as handle:\n",
        "    training_dataa = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/label_minus005.pickle', 'rb') as handle:\n",
        "    training_labelss = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etwyrue7sIYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd604413-1c3e-481c-8c3b-e741c893d446"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#using SMOTE\n",
        "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(training_dataa, training_labelss)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0, test_size=0.1)\n",
        "#x_train, x_test, y_train, y_test = train_test_split(training_dataa, training_labelss, random_state=0, test_size=0.2)\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)\n",
        "\n",
        "\n",
        "#using class weights to balance the data\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "#weights = {0:1,1:2.5}\n",
        "# convert list of labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "\n",
        "\n",
        "#Reshaping\n",
        "input_dim = X_train.shape[1]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "# Here's an MLP\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "# model.add(Dense(256))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.45))\n",
        "\n",
        "\n",
        "# model.add(Dense(128))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('logclass-bin-minus05.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "print(\"Training...\")\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=64,\n",
        "\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [es,mc],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.6584 - accuracy: 0.6457\n",
            "Epoch 00001: val_loss improved from inf to 0.57755, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6582 - accuracy: 0.6448 - val_loss: 0.5775 - val_accuracy: 0.6520\n",
            "Epoch 2/250\n",
            "386/388 [============================>.] - ETA: 0s - loss: 0.6044 - accuracy: 0.6499\n",
            "Epoch 00002: val_loss did not improve from 0.57755\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6044 - accuracy: 0.6499 - val_loss: 0.5846 - val_accuracy: 0.6562\n",
            "Epoch 3/250\n",
            "374/388 [===========================>..] - ETA: 0s - loss: 0.5914 - accuracy: 0.6670\n",
            "Epoch 00003: val_loss improved from 0.57755 to 0.55775, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5907 - accuracy: 0.6688 - val_loss: 0.5577 - val_accuracy: 0.7005\n",
            "Epoch 4/250\n",
            "385/388 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.7119\n",
            "Epoch 00004: val_loss improved from 0.55775 to 0.54070, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.7120 - val_loss: 0.5407 - val_accuracy: 0.7479\n",
            "Epoch 5/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.5524 - accuracy: 0.7259\n",
            "Epoch 00005: val_loss improved from 0.54070 to 0.51328, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5524 - accuracy: 0.7258 - val_loss: 0.5133 - val_accuracy: 0.7480\n",
            "Epoch 6/250\n",
            "373/388 [===========================>..] - ETA: 0s - loss: 0.5445 - accuracy: 0.7304\n",
            "Epoch 00006: val_loss improved from 0.51328 to 0.51264, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5435 - accuracy: 0.7316 - val_loss: 0.5126 - val_accuracy: 0.7653\n",
            "Epoch 7/250\n",
            "374/388 [===========================>..] - ETA: 0s - loss: 0.5339 - accuracy: 0.7394\n",
            "Epoch 00007: val_loss improved from 0.51264 to 0.50330, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7390 - val_loss: 0.5033 - val_accuracy: 0.7875\n",
            "Epoch 8/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.5329 - accuracy: 0.7406\n",
            "Epoch 00008: val_loss improved from 0.50330 to 0.50115, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7400 - val_loss: 0.5011 - val_accuracy: 0.7799\n",
            "Epoch 9/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.5307 - accuracy: 0.7422\n",
            "Epoch 00009: val_loss improved from 0.50115 to 0.49136, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7419 - val_loss: 0.4914 - val_accuracy: 0.7907\n",
            "Epoch 10/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7443\n",
            "Epoch 00010: val_loss did not improve from 0.49136\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7444 - val_loss: 0.5029 - val_accuracy: 0.7844\n",
            "Epoch 11/250\n",
            "388/388 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.7452\n",
            "Epoch 00011: val_loss improved from 0.49136 to 0.48482, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.7452 - val_loss: 0.4848 - val_accuracy: 0.7927\n",
            "Epoch 12/250\n",
            "388/388 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.7485\n",
            "Epoch 00012: val_loss did not improve from 0.48482\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.7485 - val_loss: 0.4883 - val_accuracy: 0.7867\n",
            "Epoch 13/250\n",
            "385/388 [============================>.] - ETA: 0s - loss: 0.5180 - accuracy: 0.7483\n",
            "Epoch 00013: val_loss improved from 0.48482 to 0.48351, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.7489 - val_loss: 0.4835 - val_accuracy: 0.7920\n",
            "Epoch 14/250\n",
            "388/388 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.7501\n",
            "Epoch 00014: val_loss did not improve from 0.48351\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.7501 - val_loss: 0.5030 - val_accuracy: 0.7869\n",
            "Epoch 15/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.5180 - accuracy: 0.7499\n",
            "Epoch 00015: val_loss did not improve from 0.48351\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7493 - val_loss: 0.5145 - val_accuracy: 0.7558\n",
            "Epoch 16/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.5170 - accuracy: 0.7523\n",
            "Epoch 00016: val_loss improved from 0.48351 to 0.47147, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7522 - val_loss: 0.4715 - val_accuracy: 0.8017\n",
            "Epoch 17/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.7516\n",
            "Epoch 00017: val_loss did not improve from 0.47147\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5147 - accuracy: 0.7516 - val_loss: 0.4790 - val_accuracy: 0.8010\n",
            "Epoch 18/250\n",
            "381/388 [============================>.] - ETA: 0s - loss: 0.5067 - accuracy: 0.7594\n",
            "Epoch 00018: val_loss did not improve from 0.47147\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.7585 - val_loss: 0.5021 - val_accuracy: 0.7751\n",
            "Epoch 19/250\n",
            "370/388 [===========================>..] - ETA: 0s - loss: 0.5049 - accuracy: 0.7592\n",
            "Epoch 00019: val_loss did not improve from 0.47147\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.7591 - val_loss: 0.4766 - val_accuracy: 0.8031\n",
            "Epoch 20/250\n",
            "369/388 [===========================>..] - ETA: 0s - loss: 0.5166 - accuracy: 0.7536\n",
            "Epoch 00020: val_loss did not improve from 0.47147\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7530 - val_loss: 0.5015 - val_accuracy: 0.7659\n",
            "Epoch 21/250\n",
            "380/388 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.7488\n",
            "Epoch 00021: val_loss improved from 0.47147 to 0.46896, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.7489 - val_loss: 0.4690 - val_accuracy: 0.7956\n",
            "Epoch 22/250\n",
            "369/388 [===========================>..] - ETA: 0s - loss: 0.5119 - accuracy: 0.7550\n",
            "Epoch 00022: val_loss did not improve from 0.46896\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5132 - accuracy: 0.7538 - val_loss: 0.4986 - val_accuracy: 0.7991\n",
            "Epoch 23/250\n",
            "380/388 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7632\n",
            "Epoch 00023: val_loss did not improve from 0.46896\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.7633 - val_loss: 0.4730 - val_accuracy: 0.7923\n",
            "Epoch 24/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.7633\n",
            "Epoch 00024: val_loss improved from 0.46896 to 0.46640, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.7630 - val_loss: 0.4664 - val_accuracy: 0.8067\n",
            "Epoch 25/250\n",
            "388/388 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.7618\n",
            "Epoch 00025: val_loss did not improve from 0.46640\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5000 - accuracy: 0.7618 - val_loss: 0.4806 - val_accuracy: 0.7910\n",
            "Epoch 26/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.7657\n",
            "Epoch 00026: val_loss did not improve from 0.46640\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7662 - val_loss: 0.4692 - val_accuracy: 0.7996\n",
            "Epoch 27/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.4946 - accuracy: 0.7689\n",
            "Epoch 00027: val_loss improved from 0.46640 to 0.46419, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7691 - val_loss: 0.4642 - val_accuracy: 0.7986\n",
            "Epoch 28/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.7715\n",
            "Epoch 00028: val_loss improved from 0.46419 to 0.45225, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7718 - val_loss: 0.4522 - val_accuracy: 0.8049\n",
            "Epoch 29/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.7682\n",
            "Epoch 00029: val_loss did not improve from 0.45225\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7676 - val_loss: 0.4922 - val_accuracy: 0.7577\n",
            "Epoch 30/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.7751\n",
            "Epoch 00030: val_loss did not improve from 0.45225\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7748 - val_loss: 0.4827 - val_accuracy: 0.7927\n",
            "Epoch 31/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.7762\n",
            "Epoch 00031: val_loss did not improve from 0.45225\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7763 - val_loss: 0.4541 - val_accuracy: 0.8020\n",
            "Epoch 32/250\n",
            "378/388 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.7711\n",
            "Epoch 00032: val_loss did not improve from 0.45225\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7711 - val_loss: 0.4687 - val_accuracy: 0.8005\n",
            "Epoch 33/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.4859 - accuracy: 0.7739\n",
            "Epoch 00033: val_loss did not improve from 0.45225\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7736 - val_loss: 0.4826 - val_accuracy: 0.7799\n",
            "Epoch 34/250\n",
            "384/388 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.7712\n",
            "Epoch 00034: val_loss improved from 0.45225 to 0.44665, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7714 - val_loss: 0.4467 - val_accuracy: 0.8020\n",
            "Epoch 35/250\n",
            "374/388 [===========================>..] - ETA: 0s - loss: 0.4843 - accuracy: 0.7770\n",
            "Epoch 00035: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7764 - val_loss: 0.4579 - val_accuracy: 0.8017\n",
            "Epoch 36/250\n",
            "380/388 [============================>.] - ETA: 0s - loss: 0.4851 - accuracy: 0.7763\n",
            "Epoch 00036: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7757 - val_loss: 0.4840 - val_accuracy: 0.7959\n",
            "Epoch 37/250\n",
            "372/388 [===========================>..] - ETA: 0s - loss: 0.4834 - accuracy: 0.7758\n",
            "Epoch 00037: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.7753 - val_loss: 0.4636 - val_accuracy: 0.7973\n",
            "Epoch 38/250\n",
            "381/388 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.7762\n",
            "Epoch 00038: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7766 - val_loss: 0.4684 - val_accuracy: 0.8001\n",
            "Epoch 39/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4823 - accuracy: 0.7799\n",
            "Epoch 00039: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7790 - val_loss: 0.4698 - val_accuracy: 0.7938\n",
            "Epoch 40/250\n",
            "376/388 [============================>.] - ETA: 0s - loss: 0.4794 - accuracy: 0.7845\n",
            "Epoch 00040: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4804 - accuracy: 0.7840 - val_loss: 0.4552 - val_accuracy: 0.8092\n",
            "Epoch 41/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.4775 - accuracy: 0.7853\n",
            "Epoch 00041: val_loss did not improve from 0.44665\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4762 - accuracy: 0.7858 - val_loss: 0.4513 - val_accuracy: 0.8097\n",
            "Epoch 42/250\n",
            "381/388 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7845\n",
            "Epoch 00042: val_loss improved from 0.44665 to 0.44592, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.7843 - val_loss: 0.4459 - val_accuracy: 0.8097\n",
            "Epoch 43/250\n",
            "385/388 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7856\n",
            "Epoch 00043: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4795 - accuracy: 0.7857 - val_loss: 0.4504 - val_accuracy: 0.8067\n",
            "Epoch 44/250\n",
            "381/388 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.7822\n",
            "Epoch 00044: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4783 - accuracy: 0.7819 - val_loss: 0.4722 - val_accuracy: 0.7962\n",
            "Epoch 45/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7868\n",
            "Epoch 00045: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4749 - accuracy: 0.7864 - val_loss: 0.4751 - val_accuracy: 0.7980\n",
            "Epoch 46/250\n",
            "385/388 [============================>.] - ETA: 0s - loss: 0.4785 - accuracy: 0.7833\n",
            "Epoch 00046: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4785 - accuracy: 0.7835 - val_loss: 0.4697 - val_accuracy: 0.7968\n",
            "Epoch 47/250\n",
            "388/388 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.7873\n",
            "Epoch 00047: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.7873 - val_loss: 0.4536 - val_accuracy: 0.8054\n",
            "Epoch 48/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.7873\n",
            "Epoch 00048: val_loss did not improve from 0.44592\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4742 - accuracy: 0.7871 - val_loss: 0.4492 - val_accuracy: 0.8046\n",
            "Epoch 49/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.4734 - accuracy: 0.7864\n",
            "Epoch 00049: val_loss improved from 0.44592 to 0.44240, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4725 - accuracy: 0.7869 - val_loss: 0.4424 - val_accuracy: 0.8110\n",
            "Epoch 50/250\n",
            "384/388 [============================>.] - ETA: 0s - loss: 0.4734 - accuracy: 0.7879\n",
            "Epoch 00050: val_loss did not improve from 0.44240\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.7880 - val_loss: 0.4454 - val_accuracy: 0.8101\n",
            "Epoch 51/250\n",
            "382/388 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.7877\n",
            "Epoch 00051: val_loss did not improve from 0.44240\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4752 - accuracy: 0.7876 - val_loss: 0.4463 - val_accuracy: 0.8023\n",
            "Epoch 52/250\n",
            "376/388 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7869\n",
            "Epoch 00052: val_loss improved from 0.44240 to 0.43808, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.7872 - val_loss: 0.4381 - val_accuracy: 0.8118\n",
            "Epoch 53/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7921\n",
            "Epoch 00053: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.7915 - val_loss: 0.4477 - val_accuracy: 0.8147\n",
            "Epoch 54/250\n",
            "375/388 [===========================>..] - ETA: 0s - loss: 0.4695 - accuracy: 0.7899\n",
            "Epoch 00054: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4690 - accuracy: 0.7901 - val_loss: 0.4644 - val_accuracy: 0.7870\n",
            "Epoch 55/250\n",
            "373/388 [===========================>..] - ETA: 0s - loss: 0.4673 - accuracy: 0.7917\n",
            "Epoch 00055: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.7918 - val_loss: 0.4385 - val_accuracy: 0.8004\n",
            "Epoch 56/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4727 - accuracy: 0.7896\n",
            "Epoch 00056: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4733 - accuracy: 0.7890 - val_loss: 0.4561 - val_accuracy: 0.8026\n",
            "Epoch 57/250\n",
            "386/388 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7903\n",
            "Epoch 00057: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.7903 - val_loss: 0.4495 - val_accuracy: 0.7943\n",
            "Epoch 58/250\n",
            "371/388 [===========================>..] - ETA: 0s - loss: 0.4723 - accuracy: 0.7893\n",
            "Epoch 00058: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4725 - accuracy: 0.7888 - val_loss: 0.4508 - val_accuracy: 0.8099\n",
            "Epoch 59/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.4722 - accuracy: 0.7872\n",
            "Epoch 00059: val_loss did not improve from 0.43808\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7871 - val_loss: 0.4447 - val_accuracy: 0.8063\n",
            "Epoch 60/250\n",
            "385/388 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.7944\n",
            "Epoch 00060: val_loss improved from 0.43808 to 0.43657, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.7947 - val_loss: 0.4366 - val_accuracy: 0.8094\n",
            "Epoch 61/250\n",
            "377/388 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.7945\n",
            "Epoch 00061: val_loss did not improve from 0.43657\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7943 - val_loss: 0.4490 - val_accuracy: 0.8138\n",
            "Epoch 62/250\n",
            "386/388 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.7874\n",
            "Epoch 00062: val_loss did not improve from 0.43657\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4742 - accuracy: 0.7875 - val_loss: 0.4610 - val_accuracy: 0.8099\n",
            "Epoch 63/250\n",
            "373/388 [===========================>..] - ETA: 0s - loss: 0.4701 - accuracy: 0.7925\n",
            "Epoch 00063: val_loss did not improve from 0.43657\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7928 - val_loss: 0.4434 - val_accuracy: 0.8088\n",
            "Epoch 64/250\n",
            "381/388 [============================>.] - ETA: 0s - loss: 0.4698 - accuracy: 0.7901\n",
            "Epoch 00064: val_loss did not improve from 0.43657\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7900 - val_loss: 0.4434 - val_accuracy: 0.8101\n",
            "Epoch 65/250\n",
            "387/388 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.7913\n",
            "Epoch 00065: val_loss improved from 0.43657 to 0.43281, saving model to logclass-bin-minus05.h5\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.7913 - val_loss: 0.4328 - val_accuracy: 0.8179\n",
            "Epoch 66/250\n",
            "386/388 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.7950\n",
            "Epoch 00066: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.7950 - val_loss: 0.4362 - val_accuracy: 0.8081\n",
            "Epoch 67/250\n",
            "370/388 [===========================>..] - ETA: 0s - loss: 0.4653 - accuracy: 0.7954\n",
            "Epoch 00067: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.7954 - val_loss: 0.4408 - val_accuracy: 0.8057\n",
            "Epoch 68/250\n",
            "376/388 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7953\n",
            "Epoch 00068: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.7949 - val_loss: 0.4552 - val_accuracy: 0.8033\n",
            "Epoch 69/250\n",
            "384/388 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.7928\n",
            "Epoch 00069: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.7930 - val_loss: 0.4417 - val_accuracy: 0.8121\n",
            "Epoch 70/250\n",
            "379/388 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.7934\n",
            "Epoch 00070: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4624 - accuracy: 0.7932 - val_loss: 0.4413 - val_accuracy: 0.8146\n",
            "Epoch 71/250\n",
            "380/388 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.7942\n",
            "Epoch 00071: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.7941 - val_loss: 0.4366 - val_accuracy: 0.8112\n",
            "Epoch 72/250\n",
            "371/388 [===========================>..] - ETA: 0s - loss: 0.4620 - accuracy: 0.7931\n",
            "Epoch 00072: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.7943 - val_loss: 0.4412 - val_accuracy: 0.8120\n",
            "Epoch 73/250\n",
            "383/388 [============================>.] - ETA: 0s - loss: 0.4579 - accuracy: 0.7990\n",
            "Epoch 00073: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.7990 - val_loss: 0.4343 - val_accuracy: 0.8112\n",
            "Epoch 74/250\n",
            "386/388 [============================>.] - ETA: 0s - loss: 0.4629 - accuracy: 0.7946\n",
            "Epoch 00074: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7943 - val_loss: 0.4466 - val_accuracy: 0.8205\n",
            "Epoch 75/250\n",
            "377/388 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.7975\n",
            "Epoch 00075: val_loss did not improve from 0.43281\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.7976 - val_loss: 0.4386 - val_accuracy: 0.8163\n",
            "Epoch 00075: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQkul0Y9wlxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5246f6f2-093b-47ef-ba08-6b74e83aaf26"
      },
      "source": [
        "sqr_model = tf.python.keras.models.load_model('logclass-bin-minus05.h5')\n",
        "adam_predictions = sqr_model.predict(X_test, verbose=1)\n",
        "# prediction and clasification report\n",
        "y_true, y_pred = [],[]\n",
        "#classes = le.classes_\n",
        "for idx, prediction in enumerate(adam_predictions): \n",
        "    y_true.append([np.argmax(y_test[idx])])\n",
        "    y_pred.append([np.argmax(prediction)])\n",
        "    \n",
        "print(sklearn.metrics.classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 0s 839us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.87      0.82      1512\n",
            "           1       0.89      0.80      0.84      1937\n",
            "\n",
            "    accuracy                           0.83      3449\n",
            "   macro avg       0.83      0.83      0.83      3449\n",
            "weighted avg       0.84      0.83      0.83      3449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu80Aps8p6hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "04c40833-f1e3-4588-8d9f-30dc8a6e500a"
      },
      "source": [
        "files.download('logclass-bin-minus05.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1e842772-7211-47b3-a1ee-6b7bfb6bb881\", \"logclass-bin-minus05.h5\", 753976)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAzaqhyWzz2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/train_mul005.pickle', 'rb') as handle:\n",
        "    training_dataa = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/binary training list/CLASSIFICATION FINAL/label_mul005.pickle', 'rb') as handle:\n",
        "    training_labelss = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5QYYvEj9dJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "779885c9-6957-48ad-cbb6-ce0a290db410"
      },
      "source": [
        "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(training_dataa, training_labelss)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0, test_size=0.1)\n",
        "#x_train, x_test, y_train, y_test = train_test_split(training_dataa, training_labelss, random_state=0, test_size=0.1)\n",
        "\n",
        "\n",
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)\n",
        "\n",
        "\n",
        "#using class weights to balance the data\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# convert list of labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "\n",
        "# weights = {0:1,1:2}\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "# Here's an MLP \n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(256))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# model.add(Dense(256))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6)\n",
        "mc = ModelCheckpoint('logclass-bin-mul05.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "print(\"Training...\")\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=16, \n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [mc,es],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1/250\n",
            "1617/1641 [============================>.] - ETA: 0s - loss: 0.7729 - accuracy: 0.6890\n",
            "Epoch 00001: val_loss improved from inf to 0.48244, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.7694 - accuracy: 0.6896 - val_loss: 0.4824 - val_accuracy: 0.7899\n",
            "Epoch 2/250\n",
            "1631/1641 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7740\n",
            "Epoch 00002: val_loss improved from 0.48244 to 0.43757, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.4945 - accuracy: 0.7738 - val_loss: 0.4376 - val_accuracy: 0.8026\n",
            "Epoch 3/250\n",
            "1634/1641 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.7957\n",
            "Epoch 00003: val_loss improved from 0.43757 to 0.41213, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.4608 - accuracy: 0.7960 - val_loss: 0.4121 - val_accuracy: 0.8043\n",
            "Epoch 4/250\n",
            "1626/1641 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8073\n",
            "Epoch 00004: val_loss improved from 0.41213 to 0.37999, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.4346 - accuracy: 0.8074 - val_loss: 0.3800 - val_accuracy: 0.8416\n",
            "Epoch 5/250\n",
            "1633/1641 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8174\n",
            "Epoch 00005: val_loss improved from 0.37999 to 0.36031, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.4141 - accuracy: 0.8174 - val_loss: 0.3603 - val_accuracy: 0.8507\n",
            "Epoch 6/250\n",
            "1639/1641 [============================>.] - ETA: 0s - loss: 0.4068 - accuracy: 0.8229\n",
            "Epoch 00006: val_loss did not improve from 0.36031\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.3603 - val_accuracy: 0.8454\n",
            "Epoch 7/250\n",
            "1634/1641 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.8252\n",
            "Epoch 00007: val_loss improved from 0.36031 to 0.34579, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3937 - accuracy: 0.8250 - val_loss: 0.3458 - val_accuracy: 0.8541\n",
            "Epoch 8/250\n",
            "1620/1641 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8289\n",
            "Epoch 00008: val_loss improved from 0.34579 to 0.34385, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3874 - accuracy: 0.8289 - val_loss: 0.3438 - val_accuracy: 0.8565\n",
            "Epoch 9/250\n",
            "1619/1641 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8353\n",
            "Epoch 00009: val_loss did not improve from 0.34385\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3821 - accuracy: 0.8357 - val_loss: 0.3440 - val_accuracy: 0.8503\n",
            "Epoch 10/250\n",
            "1626/1641 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.8384\n",
            "Epoch 00010: val_loss improved from 0.34385 to 0.32640, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3746 - accuracy: 0.8381 - val_loss: 0.3264 - val_accuracy: 0.8643\n",
            "Epoch 11/250\n",
            "1621/1641 [============================>.] - ETA: 0s - loss: 0.3663 - accuracy: 0.8422\n",
            "Epoch 00011: val_loss did not improve from 0.32640\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3662 - accuracy: 0.8421 - val_loss: 0.3365 - val_accuracy: 0.8618\n",
            "Epoch 12/250\n",
            "1638/1641 [============================>.] - ETA: 0s - loss: 0.3608 - accuracy: 0.8457\n",
            "Epoch 00012: val_loss improved from 0.32640 to 0.32381, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3610 - accuracy: 0.8457 - val_loss: 0.3238 - val_accuracy: 0.8756\n",
            "Epoch 13/250\n",
            "1628/1641 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8493\n",
            "Epoch 00013: val_loss improved from 0.32381 to 0.31958, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3573 - accuracy: 0.8494 - val_loss: 0.3196 - val_accuracy: 0.8792\n",
            "Epoch 14/250\n",
            "1624/1641 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8508\n",
            "Epoch 00014: val_loss did not improve from 0.31958\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3532 - accuracy: 0.8505 - val_loss: 0.3227 - val_accuracy: 0.8746\n",
            "Epoch 15/250\n",
            "1630/1641 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.8505\n",
            "Epoch 00015: val_loss improved from 0.31958 to 0.31115, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3516 - accuracy: 0.8507 - val_loss: 0.3111 - val_accuracy: 0.8739\n",
            "Epoch 16/250\n",
            "1629/1641 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8549\n",
            "Epoch 00016: val_loss improved from 0.31115 to 0.30821, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3435 - accuracy: 0.8551 - val_loss: 0.3082 - val_accuracy: 0.8716\n",
            "Epoch 17/250\n",
            "1627/1641 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8568\n",
            "Epoch 00017: val_loss improved from 0.30821 to 0.30021, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3388 - accuracy: 0.8567 - val_loss: 0.3002 - val_accuracy: 0.8797\n",
            "Epoch 18/250\n",
            "1632/1641 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.8595\n",
            "Epoch 00018: val_loss did not improve from 0.30021\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3366 - accuracy: 0.8595 - val_loss: 0.3047 - val_accuracy: 0.8781\n",
            "Epoch 19/250\n",
            "1639/1641 [============================>.] - ETA: 0s - loss: 0.3341 - accuracy: 0.8618\n",
            "Epoch 00019: val_loss improved from 0.30021 to 0.29824, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.8618 - val_loss: 0.2982 - val_accuracy: 0.8838\n",
            "Epoch 20/250\n",
            "1620/1641 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8637\n",
            "Epoch 00020: val_loss improved from 0.29824 to 0.29567, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3299 - accuracy: 0.8635 - val_loss: 0.2957 - val_accuracy: 0.8827\n",
            "Epoch 21/250\n",
            "1624/1641 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.8634\n",
            "Epoch 00021: val_loss improved from 0.29567 to 0.28724, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3278 - accuracy: 0.8632 - val_loss: 0.2872 - val_accuracy: 0.8844\n",
            "Epoch 22/250\n",
            "1630/1641 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8645\n",
            "Epoch 00022: val_loss did not improve from 0.28724\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3232 - accuracy: 0.8645 - val_loss: 0.2914 - val_accuracy: 0.8861\n",
            "Epoch 23/250\n",
            "1629/1641 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8656\n",
            "Epoch 00023: val_loss improved from 0.28724 to 0.28448, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3238 - accuracy: 0.8656 - val_loss: 0.2845 - val_accuracy: 0.8877\n",
            "Epoch 24/250\n",
            "1624/1641 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.8677\n",
            "Epoch 00024: val_loss did not improve from 0.28448\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3194 - accuracy: 0.8679 - val_loss: 0.2888 - val_accuracy: 0.8813\n",
            "Epoch 25/250\n",
            "1616/1641 [============================>.] - ETA: 0s - loss: 0.3163 - accuracy: 0.8702\n",
            "Epoch 00025: val_loss improved from 0.28448 to 0.28267, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3161 - accuracy: 0.8702 - val_loss: 0.2827 - val_accuracy: 0.8883\n",
            "Epoch 26/250\n",
            "1620/1641 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8707\n",
            "Epoch 00026: val_loss did not improve from 0.28267\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8708 - val_loss: 0.2870 - val_accuracy: 0.8871\n",
            "Epoch 27/250\n",
            "1634/1641 [============================>.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8720\n",
            "Epoch 00027: val_loss improved from 0.28267 to 0.27842, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3126 - accuracy: 0.8720 - val_loss: 0.2784 - val_accuracy: 0.8891\n",
            "Epoch 28/250\n",
            "1624/1641 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.8713\n",
            "Epoch 00028: val_loss improved from 0.27842 to 0.27707, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8713 - val_loss: 0.2771 - val_accuracy: 0.8925\n",
            "Epoch 29/250\n",
            "1622/1641 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8728\n",
            "Epoch 00029: val_loss did not improve from 0.27707\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8727 - val_loss: 0.2822 - val_accuracy: 0.8876\n",
            "Epoch 30/250\n",
            "1629/1641 [============================>.] - ETA: 0s - loss: 0.3077 - accuracy: 0.8727\n",
            "Epoch 00030: val_loss improved from 0.27707 to 0.27412, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8727 - val_loss: 0.2741 - val_accuracy: 0.8890\n",
            "Epoch 31/250\n",
            "1620/1641 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8752\n",
            "Epoch 00031: val_loss did not improve from 0.27412\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8750 - val_loss: 0.2760 - val_accuracy: 0.8963\n",
            "Epoch 32/250\n",
            "1620/1641 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.8748\n",
            "Epoch 00032: val_loss did not improve from 0.27412\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8749 - val_loss: 0.2809 - val_accuracy: 0.8789\n",
            "Epoch 33/250\n",
            "1627/1641 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8776\n",
            "Epoch 00033: val_loss improved from 0.27412 to 0.26829, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2993 - accuracy: 0.8776 - val_loss: 0.2683 - val_accuracy: 0.8902\n",
            "Epoch 34/250\n",
            "1633/1641 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8770\n",
            "Epoch 00034: val_loss improved from 0.26829 to 0.26796, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.8768 - val_loss: 0.2680 - val_accuracy: 0.8982\n",
            "Epoch 35/250\n",
            "1617/1641 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.8769\n",
            "Epoch 00035: val_loss did not improve from 0.26796\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.3015 - accuracy: 0.8769 - val_loss: 0.2724 - val_accuracy: 0.8950\n",
            "Epoch 36/250\n",
            "1627/1641 [============================>.] - ETA: 0s - loss: 0.2965 - accuracy: 0.8792\n",
            "Epoch 00036: val_loss did not improve from 0.26796\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2963 - accuracy: 0.8794 - val_loss: 0.2755 - val_accuracy: 0.8963\n",
            "Epoch 37/250\n",
            "1636/1641 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.8803\n",
            "Epoch 00037: val_loss improved from 0.26796 to 0.26400, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.8800 - val_loss: 0.2640 - val_accuracy: 0.8961\n",
            "Epoch 38/250\n",
            "1639/1641 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.8806\n",
            "Epoch 00038: val_loss improved from 0.26400 to 0.26022, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.8807 - val_loss: 0.2602 - val_accuracy: 0.8989\n",
            "Epoch 39/250\n",
            "1629/1641 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8805\n",
            "Epoch 00039: val_loss did not improve from 0.26022\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2950 - accuracy: 0.8804 - val_loss: 0.2646 - val_accuracy: 0.8999\n",
            "Epoch 40/250\n",
            "1622/1641 [============================>.] - ETA: 0s - loss: 0.2931 - accuracy: 0.8809\n",
            "Epoch 00040: val_loss improved from 0.26022 to 0.25920, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.8813 - val_loss: 0.2592 - val_accuracy: 0.9021\n",
            "Epoch 41/250\n",
            "1624/1641 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8824\n",
            "Epoch 00041: val_loss did not improve from 0.25920\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2894 - accuracy: 0.8827 - val_loss: 0.2696 - val_accuracy: 0.8973\n",
            "Epoch 42/250\n",
            "1630/1641 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.8819\n",
            "Epoch 00042: val_loss did not improve from 0.25920\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2905 - accuracy: 0.8821 - val_loss: 0.2707 - val_accuracy: 0.8950\n",
            "Epoch 43/250\n",
            "1632/1641 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.8840\n",
            "Epoch 00043: val_loss improved from 0.25920 to 0.24717, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2862 - accuracy: 0.8842 - val_loss: 0.2472 - val_accuracy: 0.9033\n",
            "Epoch 44/250\n",
            "1622/1641 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.8868\n",
            "Epoch 00044: val_loss did not improve from 0.24717\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2860 - accuracy: 0.8867 - val_loss: 0.2624 - val_accuracy: 0.8993\n",
            "Epoch 45/250\n",
            "1637/1641 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.8855\n",
            "Epoch 00045: val_loss did not improve from 0.24717\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2864 - accuracy: 0.8855 - val_loss: 0.2631 - val_accuracy: 0.9021\n",
            "Epoch 46/250\n",
            "1628/1641 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.8876\n",
            "Epoch 00046: val_loss improved from 0.24717 to 0.24698, saving model to logclass-bin-mul05.h5\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2810 - accuracy: 0.8876 - val_loss: 0.2470 - val_accuracy: 0.9050\n",
            "Epoch 47/250\n",
            "1639/1641 [============================>.] - ETA: 0s - loss: 0.2773 - accuracy: 0.8875\n",
            "Epoch 00047: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2774 - accuracy: 0.8875 - val_loss: 0.2520 - val_accuracy: 0.9077\n",
            "Epoch 48/250\n",
            "1626/1641 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.8875\n",
            "Epoch 00048: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2800 - accuracy: 0.8874 - val_loss: 0.2591 - val_accuracy: 0.8987\n",
            "Epoch 49/250\n",
            "1632/1641 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.8882\n",
            "Epoch 00049: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2790 - accuracy: 0.8881 - val_loss: 0.2560 - val_accuracy: 0.9016\n",
            "Epoch 50/250\n",
            "1633/1641 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.8885\n",
            "Epoch 00050: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 4s 2ms/step - loss: 0.2822 - accuracy: 0.8883 - val_loss: 0.2554 - val_accuracy: 0.9005\n",
            "Epoch 51/250\n",
            "1628/1641 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8884\n",
            "Epoch 00051: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2769 - accuracy: 0.8883 - val_loss: 0.2570 - val_accuracy: 0.8952\n",
            "Epoch 52/250\n",
            "1633/1641 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.8897\n",
            "Epoch 00052: val_loss did not improve from 0.24698\n",
            "1641/1641 [==============================] - 3s 2ms/step - loss: 0.2758 - accuracy: 0.8895 - val_loss: 0.2539 - val_accuracy: 0.9030\n",
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elHPVYPhCSox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dd8533b3-50cd-4a7d-f549-dbd15af9ac53"
      },
      "source": [
        "sqr_model = tf.python.keras.models.load_model('logclass-bin-mul05.h5')\n",
        "adam_predictions = sqr_model.predict(X_test, verbose=1)\n",
        "# prediction and clasification report\n",
        "y_true, y_pred = [],[]\n",
        "#classes = le.classes_\n",
        "for idx, prediction in enumerate(adam_predictions): \n",
        "    y_true.append([np.argmax(y_test[idx])])\n",
        "    y_pred.append([np.argmax(prediction)])\n",
        "    \n",
        "print(sklearn.metrics.classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 982us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.98      0.91      1526\n",
            "           1       0.99      0.86      0.92      2121\n",
            "\n",
            "    accuracy                           0.91      3647\n",
            "   macro avg       0.91      0.92      0.91      3647\n",
            "weighted avg       0.93      0.91      0.92      3647\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2VeqC65V6Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9950b996-340f-44e4-9797-6ab683b3d20c"
      },
      "source": [
        "files.download('logclass-bin-mul05.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_420febf9-d993-4293-8831-295f6e1c2212\", \"logclass-bin-mul05.h5\", 1468648)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifHnIiXCCaDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/New Training Data/binary/005/train_mul005.pickle', 'rb') as handle:\n",
        "    training_dataa = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/New Training Data/binary/005/label_mul005.pickle', 'rb') as handle:\n",
        "    training_labelss = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3el3U1s3kyiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c4c3bd8-74dd-4644-f82f-720111ba11db"
      },
      "source": [
        "np.unique(training_labelss, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([10331,  4389]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjDFHIOfU4eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5781a45b-887f-4d28-98e6-a711adc08497"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(training_dataa, training_labelss, random_state=0, test_size=0.1)\n",
        "\n",
        "\n",
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)\n",
        "\n",
        "\n",
        "#using class weights to balance the data\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# convert list of labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "\n",
        "# weights = {0:1,1:2}\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "# Here's an MLP \n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6)\n",
        "mc = ModelCheckpoint('bin-mul05.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "print(\"Training...\")\n",
        "history = model.fit(X_train, y_train, nb_epoch=250, batch_size=64, class_weight=class_weights,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [mc,es],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10598 samples, validate on 2650 samples\n",
            "Epoch 1/250\n",
            "10598/10598 [==============================] - 1s 76us/step - loss: 0.6924 - accuracy: 0.5448 - val_loss: 0.6914 - val_accuracy: 0.6755\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69139, saving model to bin-mul05.h5\n",
            "Epoch 2/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.6883 - accuracy: 0.5593 - val_loss: 0.6840 - val_accuracy: 0.7091\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69139 to 0.68396, saving model to bin-mul05.h5\n",
            "Epoch 3/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.6771 - accuracy: 0.6110 - val_loss: 0.6660 - val_accuracy: 0.6717\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68396 to 0.66602, saving model to bin-mul05.h5\n",
            "Epoch 4/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.6574 - accuracy: 0.6254 - val_loss: 0.6400 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.66602 to 0.64004, saving model to bin-mul05.h5\n",
            "Epoch 5/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.6321 - accuracy: 0.6521 - val_loss: 0.6107 - val_accuracy: 0.6974\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.64004 to 0.61073, saving model to bin-mul05.h5\n",
            "Epoch 6/250\n",
            "10598/10598 [==============================] - 0s 46us/step - loss: 0.6032 - accuracy: 0.6906 - val_loss: 0.5787 - val_accuracy: 0.7355\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.61073 to 0.57867, saving model to bin-mul05.h5\n",
            "Epoch 7/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.5718 - accuracy: 0.7274 - val_loss: 0.5478 - val_accuracy: 0.7596\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.57867 to 0.54781, saving model to bin-mul05.h5\n",
            "Epoch 8/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.5459 - accuracy: 0.7583 - val_loss: 0.5217 - val_accuracy: 0.7898\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.54781 to 0.52165, saving model to bin-mul05.h5\n",
            "Epoch 9/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.5181 - accuracy: 0.7806 - val_loss: 0.4992 - val_accuracy: 0.7970\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.52165 to 0.49918, saving model to bin-mul05.h5\n",
            "Epoch 10/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.4980 - accuracy: 0.7958 - val_loss: 0.4798 - val_accuracy: 0.8098\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.49918 to 0.47984, saving model to bin-mul05.h5\n",
            "Epoch 11/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.4746 - accuracy: 0.8139 - val_loss: 0.4640 - val_accuracy: 0.8015\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.47984 to 0.46405, saving model to bin-mul05.h5\n",
            "Epoch 12/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.4647 - accuracy: 0.8146 - val_loss: 0.4486 - val_accuracy: 0.8200\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.46405 to 0.44860, saving model to bin-mul05.h5\n",
            "Epoch 13/250\n",
            "10598/10598 [==============================] - 0s 42us/step - loss: 0.4454 - accuracy: 0.8248 - val_loss: 0.4382 - val_accuracy: 0.8143\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.44860 to 0.43822, saving model to bin-mul05.h5\n",
            "Epoch 14/250\n",
            "10598/10598 [==============================] - 0s 47us/step - loss: 0.4423 - accuracy: 0.8275 - val_loss: 0.4286 - val_accuracy: 0.8328\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.43822 to 0.42858, saving model to bin-mul05.h5\n",
            "Epoch 15/250\n",
            "10598/10598 [==============================] - 0s 46us/step - loss: 0.4257 - accuracy: 0.8362 - val_loss: 0.4200 - val_accuracy: 0.8336\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.42858 to 0.42000, saving model to bin-mul05.h5\n",
            "Epoch 16/250\n",
            "10598/10598 [==============================] - 1s 48us/step - loss: 0.4141 - accuracy: 0.8425 - val_loss: 0.4128 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.42000 to 0.41280, saving model to bin-mul05.h5\n",
            "Epoch 17/250\n",
            "10598/10598 [==============================] - 1s 47us/step - loss: 0.4030 - accuracy: 0.8441 - val_loss: 0.4052 - val_accuracy: 0.8396\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.41280 to 0.40525, saving model to bin-mul05.h5\n",
            "Epoch 18/250\n",
            "10598/10598 [==============================] - 1s 50us/step - loss: 0.4033 - accuracy: 0.8448 - val_loss: 0.3992 - val_accuracy: 0.8449\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.40525 to 0.39918, saving model to bin-mul05.h5\n",
            "Epoch 19/250\n",
            "10598/10598 [==============================] - 1s 48us/step - loss: 0.3926 - accuracy: 0.8465 - val_loss: 0.3967 - val_accuracy: 0.8491\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.39918 to 0.39675, saving model to bin-mul05.h5\n",
            "Epoch 20/250\n",
            "10598/10598 [==============================] - 1s 50us/step - loss: 0.3816 - accuracy: 0.8540 - val_loss: 0.3916 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.39675 to 0.39160, saving model to bin-mul05.h5\n",
            "Epoch 21/250\n",
            "10598/10598 [==============================] - 1s 48us/step - loss: 0.3777 - accuracy: 0.8563 - val_loss: 0.3827 - val_accuracy: 0.8445\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.39160 to 0.38275, saving model to bin-mul05.h5\n",
            "Epoch 22/250\n",
            "10598/10598 [==============================] - 1s 49us/step - loss: 0.3711 - accuracy: 0.8606 - val_loss: 0.3793 - val_accuracy: 0.8475\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.38275 to 0.37927, saving model to bin-mul05.h5\n",
            "Epoch 23/250\n",
            "10598/10598 [==============================] - 1s 48us/step - loss: 0.3620 - accuracy: 0.8584 - val_loss: 0.3759 - val_accuracy: 0.8506\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.37927 to 0.37587, saving model to bin-mul05.h5\n",
            "Epoch 24/250\n",
            "10598/10598 [==============================] - 1s 47us/step - loss: 0.3586 - accuracy: 0.8640 - val_loss: 0.3741 - val_accuracy: 0.8562\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.37587 to 0.37410, saving model to bin-mul05.h5\n",
            "Epoch 25/250\n",
            "10598/10598 [==============================] - 0s 46us/step - loss: 0.3529 - accuracy: 0.8663 - val_loss: 0.3683 - val_accuracy: 0.8540\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.37410 to 0.36832, saving model to bin-mul05.h5\n",
            "Epoch 26/250\n",
            "10598/10598 [==============================] - 1s 66us/step - loss: 0.3399 - accuracy: 0.8719 - val_loss: 0.3669 - val_accuracy: 0.8517\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.36832 to 0.36693, saving model to bin-mul05.h5\n",
            "Epoch 27/250\n",
            "10598/10598 [==============================] - 1s 62us/step - loss: 0.3382 - accuracy: 0.8708 - val_loss: 0.3643 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.36693 to 0.36427, saving model to bin-mul05.h5\n",
            "Epoch 28/250\n",
            "10598/10598 [==============================] - 1s 61us/step - loss: 0.3361 - accuracy: 0.8748 - val_loss: 0.3648 - val_accuracy: 0.8615\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.36427\n",
            "Epoch 29/250\n",
            "10598/10598 [==============================] - 1s 51us/step - loss: 0.3267 - accuracy: 0.8784 - val_loss: 0.3616 - val_accuracy: 0.8574\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.36427 to 0.36161, saving model to bin-mul05.h5\n",
            "Epoch 30/250\n",
            "10598/10598 [==============================] - 1s 50us/step - loss: 0.3265 - accuracy: 0.8782 - val_loss: 0.3578 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.36161 to 0.35778, saving model to bin-mul05.h5\n",
            "Epoch 31/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.3213 - accuracy: 0.8823 - val_loss: 0.3558 - val_accuracy: 0.8585\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.35778 to 0.35580, saving model to bin-mul05.h5\n",
            "Epoch 32/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.3219 - accuracy: 0.8808 - val_loss: 0.3558 - val_accuracy: 0.8619\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.35580 to 0.35577, saving model to bin-mul05.h5\n",
            "Epoch 33/250\n",
            "10598/10598 [==============================] - 0s 42us/step - loss: 0.3170 - accuracy: 0.8780 - val_loss: 0.3558 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.35577\n",
            "Epoch 34/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.3062 - accuracy: 0.8862 - val_loss: 0.3520 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.35577 to 0.35205, saving model to bin-mul05.h5\n",
            "Epoch 35/250\n",
            "10598/10598 [==============================] - 0s 42us/step - loss: 0.3008 - accuracy: 0.8893 - val_loss: 0.3522 - val_accuracy: 0.8604\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.35205\n",
            "Epoch 36/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.3116 - accuracy: 0.8835 - val_loss: 0.3529 - val_accuracy: 0.8679\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.35205\n",
            "Epoch 37/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2972 - accuracy: 0.8916 - val_loss: 0.3523 - val_accuracy: 0.8687\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.35205\n",
            "Epoch 38/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2932 - accuracy: 0.8923 - val_loss: 0.3491 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.35205 to 0.34911, saving model to bin-mul05.h5\n",
            "Epoch 39/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.2948 - accuracy: 0.8917 - val_loss: 0.3527 - val_accuracy: 0.8728\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.34911\n",
            "Epoch 40/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2922 - accuracy: 0.8948 - val_loss: 0.3474 - val_accuracy: 0.8615\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.34911 to 0.34740, saving model to bin-mul05.h5\n",
            "Epoch 41/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.2822 - accuracy: 0.8950 - val_loss: 0.3472 - val_accuracy: 0.8702\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.34740 to 0.34724, saving model to bin-mul05.h5\n",
            "Epoch 42/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2837 - accuracy: 0.8946 - val_loss: 0.3460 - val_accuracy: 0.8642\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.34724 to 0.34602, saving model to bin-mul05.h5\n",
            "Epoch 43/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2767 - accuracy: 0.8986 - val_loss: 0.3507 - val_accuracy: 0.8743\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.34602\n",
            "Epoch 44/250\n",
            "10598/10598 [==============================] - 0s 42us/step - loss: 0.2750 - accuracy: 0.8991 - val_loss: 0.3491 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.34602\n",
            "Epoch 45/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2670 - accuracy: 0.9024 - val_loss: 0.3505 - val_accuracy: 0.8747\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.34602\n",
            "Epoch 46/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.2695 - accuracy: 0.9060 - val_loss: 0.3459 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.34602 to 0.34594, saving model to bin-mul05.h5\n",
            "Epoch 47/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2589 - accuracy: 0.9056 - val_loss: 0.3507 - val_accuracy: 0.8743\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.34594\n",
            "Epoch 48/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.2654 - accuracy: 0.9030 - val_loss: 0.3468 - val_accuracy: 0.8713\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.34594\n",
            "Epoch 49/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.2606 - accuracy: 0.9028 - val_loss: 0.3463 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.34594\n",
            "Epoch 50/250\n",
            "10598/10598 [==============================] - 0s 43us/step - loss: 0.2580 - accuracy: 0.9047 - val_loss: 0.3524 - val_accuracy: 0.8755\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.34594\n",
            "Epoch 51/250\n",
            "10598/10598 [==============================] - 0s 45us/step - loss: 0.2486 - accuracy: 0.9104 - val_loss: 0.3501 - val_accuracy: 0.8630\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.34594\n",
            "Epoch 52/250\n",
            "10598/10598 [==============================] - 0s 44us/step - loss: 0.2507 - accuracy: 0.9091 - val_loss: 0.3476 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.34594\n",
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu44IX4aVTJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ab8aac26-789a-4413-9b9d-c65bb1779849"
      },
      "source": [
        "sqr_model = tf.python.keras.models.load_model('bin-mul05.h5')\n",
        "adam_predictions = sqr_model.predict(X_test, verbose=1)\n",
        "# prediction and clasification report\n",
        "y_true, y_pred = [],[]\n",
        "#classes = le.classes_\n",
        "for idx, prediction in enumerate(adam_predictions): \n",
        "    y_true.append([np.argmax(y_test[idx])])\n",
        "    y_pred.append([np.argmax(prediction)])\n",
        "    \n",
        "print(sklearn.metrics.classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91       976\n",
            "           1       0.85      0.75      0.80       496\n",
            "\n",
            "    accuracy                           0.87      1472\n",
            "   macro avg       0.87      0.84      0.85      1472\n",
            "weighted avg       0.87      0.87      0.87      1472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t4BmyjNl9zL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ba73c497-1770-46e3-e1eb-cb9e12a5e24f"
      },
      "source": [
        "files.download('bin-mul05.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_47f15d08-788d-4ac0-9088-a6c6fe84cea3\", \"bin-mul05.h5\", 421568)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF2_AL2YZ4Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Auto-AI-2019-20/New Training Data/cond_prob/train_reg_sqr.pickle', 'rb') as handle:\n",
        "    training_dataa = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/Auto-AI-2019-20/New Training Data/cond_prob/label_reg_sqr.pickle', 'rb') as handle:\n",
        "    training_labelss = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI-tIh_oZ_ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc952cfb-20d5-4665-f0ab-7e4c5db3f97b"
      },
      "source": [
        "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(training_dataa, training_labelss)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0, test_size=0.1)\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)\n",
        "\n",
        "\n",
        "#using class weights to balance the data\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# convert list of labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "# Here's an MLP\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=input_dim))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(128))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('lnr-cp-sqr01.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "print(\"Training...\")\n",
        "history = model.fit(X_train, y_train, nb_epoch=250, batch_size=16,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [mc,es],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Train on 842 samples, validate on 211 samples\n",
            "Epoch 1/250\n",
            "842/842 [==============================] - 0s 275us/step - loss: 0.6950 - accuracy: 0.4941 - val_loss: 0.6979 - val_accuracy: 0.4313\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69786, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 2/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.6939 - accuracy: 0.5083 - val_loss: 0.6963 - val_accuracy: 0.4550\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69786 to 0.69628, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 3/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.6916 - accuracy: 0.5249 - val_loss: 0.6953 - val_accuracy: 0.4787\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.69628 to 0.69527, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 4/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.6897 - accuracy: 0.5451 - val_loss: 0.6954 - val_accuracy: 0.4882\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.69527\n",
            "Epoch 5/250\n",
            "842/842 [==============================] - 0s 108us/step - loss: 0.6891 - accuracy: 0.5273 - val_loss: 0.6942 - val_accuracy: 0.5024\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.69527 to 0.69424, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 6/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.6887 - accuracy: 0.5249 - val_loss: 0.6930 - val_accuracy: 0.5071\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.69424 to 0.69300, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 7/250\n",
            "842/842 [==============================] - 0s 101us/step - loss: 0.6892 - accuracy: 0.5499 - val_loss: 0.6929 - val_accuracy: 0.5071\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.69300 to 0.69291, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 8/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.6847 - accuracy: 0.5523 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.69291 to 0.69190, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 9/250\n",
            "842/842 [==============================] - 0s 112us/step - loss: 0.6826 - accuracy: 0.5558 - val_loss: 0.6901 - val_accuracy: 0.5213\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.69190 to 0.69014, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 10/250\n",
            "842/842 [==============================] - 0s 108us/step - loss: 0.6815 - accuracy: 0.5475 - val_loss: 0.6877 - val_accuracy: 0.5403\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.69014 to 0.68768, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 11/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.6780 - accuracy: 0.5796 - val_loss: 0.6863 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.68768 to 0.68631, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 12/250\n",
            "842/842 [==============================] - 0s 109us/step - loss: 0.6717 - accuracy: 0.5891 - val_loss: 0.6851 - val_accuracy: 0.5735\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.68631 to 0.68511, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 13/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.6730 - accuracy: 0.5926 - val_loss: 0.6842 - val_accuracy: 0.5687\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.68511 to 0.68416, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 14/250\n",
            "842/842 [==============================] - 0s 115us/step - loss: 0.6712 - accuracy: 0.5903 - val_loss: 0.6804 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.68416 to 0.68041, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 15/250\n",
            "842/842 [==============================] - 0s 120us/step - loss: 0.6660 - accuracy: 0.6425 - val_loss: 0.6775 - val_accuracy: 0.6114\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.68041 to 0.67747, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 16/250\n",
            "842/842 [==============================] - 0s 122us/step - loss: 0.6648 - accuracy: 0.6176 - val_loss: 0.6744 - val_accuracy: 0.6303\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.67747 to 0.67444, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 17/250\n",
            "842/842 [==============================] - 0s 117us/step - loss: 0.6597 - accuracy: 0.6532 - val_loss: 0.6718 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.67444 to 0.67178, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 18/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.6530 - accuracy: 0.6627 - val_loss: 0.6684 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.67178 to 0.66844, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 19/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.6545 - accuracy: 0.6295 - val_loss: 0.6654 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.66844 to 0.66537, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 20/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.6479 - accuracy: 0.6651 - val_loss: 0.6620 - val_accuracy: 0.6445\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.66537 to 0.66204, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 21/250\n",
            "842/842 [==============================] - 0s 108us/step - loss: 0.6416 - accuracy: 0.6734 - val_loss: 0.6582 - val_accuracy: 0.6635\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.66204 to 0.65824, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 22/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.6380 - accuracy: 0.6805 - val_loss: 0.6552 - val_accuracy: 0.6540\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.65824 to 0.65519, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 23/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.6295 - accuracy: 0.7090 - val_loss: 0.6511 - val_accuracy: 0.6445\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.65519 to 0.65112, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 24/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.6289 - accuracy: 0.6817 - val_loss: 0.6467 - val_accuracy: 0.6588\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.65112 to 0.64668, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 25/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.6239 - accuracy: 0.7031 - val_loss: 0.6414 - val_accuracy: 0.6919\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.64668 to 0.64143, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 26/250\n",
            "842/842 [==============================] - 0s 101us/step - loss: 0.6119 - accuracy: 0.7138 - val_loss: 0.6367 - val_accuracy: 0.6825\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.64143 to 0.63669, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 27/250\n",
            "842/842 [==============================] - 0s 116us/step - loss: 0.6071 - accuracy: 0.7375 - val_loss: 0.6318 - val_accuracy: 0.6730\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.63669 to 0.63180, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 28/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.5949 - accuracy: 0.7280 - val_loss: 0.6265 - val_accuracy: 0.6825\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.63180 to 0.62651, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 29/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.5935 - accuracy: 0.7031 - val_loss: 0.6203 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.62651 to 0.62035, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 30/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.5806 - accuracy: 0.7375 - val_loss: 0.6155 - val_accuracy: 0.6967\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.62035 to 0.61554, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 31/250\n",
            "842/842 [==============================] - 0s 109us/step - loss: 0.5849 - accuracy: 0.7542 - val_loss: 0.6101 - val_accuracy: 0.6919\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.61554 to 0.61007, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 32/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.5721 - accuracy: 0.7470 - val_loss: 0.6037 - val_accuracy: 0.7156\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.61007 to 0.60367, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 33/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.5644 - accuracy: 0.7518 - val_loss: 0.5985 - val_accuracy: 0.7346\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.60367 to 0.59849, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 34/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.5656 - accuracy: 0.7506 - val_loss: 0.5941 - val_accuracy: 0.7441\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.59849 to 0.59409, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 35/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.5489 - accuracy: 0.7708 - val_loss: 0.5865 - val_accuracy: 0.7536\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.59409 to 0.58652, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 36/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.5418 - accuracy: 0.7767 - val_loss: 0.5816 - val_accuracy: 0.7346\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.58652 to 0.58157, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 37/250\n",
            "842/842 [==============================] - 0s 122us/step - loss: 0.5385 - accuracy: 0.7696 - val_loss: 0.5755 - val_accuracy: 0.7441\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.58157 to 0.57547, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 38/250\n",
            "842/842 [==============================] - 0s 120us/step - loss: 0.5199 - accuracy: 0.7767 - val_loss: 0.5707 - val_accuracy: 0.7536\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.57547 to 0.57067, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 39/250\n",
            "842/842 [==============================] - 0s 122us/step - loss: 0.5196 - accuracy: 0.7720 - val_loss: 0.5667 - val_accuracy: 0.7393\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.57067 to 0.56671, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 40/250\n",
            "842/842 [==============================] - 0s 127us/step - loss: 0.5125 - accuracy: 0.7969 - val_loss: 0.5599 - val_accuracy: 0.7536\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.56671 to 0.55990, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 41/250\n",
            "842/842 [==============================] - 0s 126us/step - loss: 0.5074 - accuracy: 0.8064 - val_loss: 0.5532 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.55990 to 0.55320, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 42/250\n",
            "842/842 [==============================] - 0s 124us/step - loss: 0.4896 - accuracy: 0.8207 - val_loss: 0.5471 - val_accuracy: 0.7725\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.55320 to 0.54711, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 43/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.4858 - accuracy: 0.8088 - val_loss: 0.5421 - val_accuracy: 0.7725\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.54711 to 0.54206, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 44/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.4756 - accuracy: 0.8230 - val_loss: 0.5362 - val_accuracy: 0.7725\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.54206 to 0.53617, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 45/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.4774 - accuracy: 0.8242 - val_loss: 0.5316 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.53617 to 0.53159, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 46/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.4664 - accuracy: 0.8207 - val_loss: 0.5241 - val_accuracy: 0.7867\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.53159 to 0.52408, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 47/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.4564 - accuracy: 0.8409 - val_loss: 0.5180 - val_accuracy: 0.7867\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.52408 to 0.51804, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 48/250\n",
            "842/842 [==============================] - 0s 111us/step - loss: 0.4462 - accuracy: 0.8290 - val_loss: 0.5133 - val_accuracy: 0.8009\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.51804 to 0.51329, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 49/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.4482 - accuracy: 0.8314 - val_loss: 0.5067 - val_accuracy: 0.8104\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.51329 to 0.50669, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 50/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.4346 - accuracy: 0.8456 - val_loss: 0.5047 - val_accuracy: 0.7962\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.50669 to 0.50467, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 51/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.4259 - accuracy: 0.8575 - val_loss: 0.5014 - val_accuracy: 0.8057\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.50467 to 0.50137, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 52/250\n",
            "842/842 [==============================] - 0s 112us/step - loss: 0.4218 - accuracy: 0.8432 - val_loss: 0.4932 - val_accuracy: 0.8199\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.50137 to 0.49316, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 53/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.4166 - accuracy: 0.8480 - val_loss: 0.4904 - val_accuracy: 0.8104\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.49316 to 0.49041, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 54/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.4252 - accuracy: 0.8432 - val_loss: 0.4853 - val_accuracy: 0.8199\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.49041 to 0.48529, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 55/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.4149 - accuracy: 0.8504 - val_loss: 0.4803 - val_accuracy: 0.8199\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.48529 to 0.48026, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 56/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.4111 - accuracy: 0.8468 - val_loss: 0.4763 - val_accuracy: 0.8152\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.48026 to 0.47628, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 57/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.4035 - accuracy: 0.8515 - val_loss: 0.4699 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.47628 to 0.46989, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 58/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.4026 - accuracy: 0.8575 - val_loss: 0.4667 - val_accuracy: 0.8389\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.46989 to 0.46667, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 59/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3800 - accuracy: 0.8646 - val_loss: 0.4634 - val_accuracy: 0.8389\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.46667 to 0.46337, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 60/250\n",
            "842/842 [==============================] - 0s 101us/step - loss: 0.3735 - accuracy: 0.8599 - val_loss: 0.4589 - val_accuracy: 0.8389\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.46337 to 0.45894, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 61/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3847 - accuracy: 0.8682 - val_loss: 0.4592 - val_accuracy: 0.8341\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.45894\n",
            "Epoch 62/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3683 - accuracy: 0.8729 - val_loss: 0.4534 - val_accuracy: 0.8389\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.45894 to 0.45341, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 63/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.3536 - accuracy: 0.8800 - val_loss: 0.4474 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.45341 to 0.44743, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 64/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3578 - accuracy: 0.8705 - val_loss: 0.4431 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.44743 to 0.44312, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 65/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.3398 - accuracy: 0.8812 - val_loss: 0.4409 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.44312 to 0.44089, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 66/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.3339 - accuracy: 0.8943 - val_loss: 0.4369 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.44089 to 0.43689, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 67/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.3558 - accuracy: 0.8658 - val_loss: 0.4349 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.43689 to 0.43487, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 68/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.3408 - accuracy: 0.8872 - val_loss: 0.4311 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.43487 to 0.43112, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 69/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.3430 - accuracy: 0.8741 - val_loss: 0.4273 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.43112 to 0.42731, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 70/250\n",
            "842/842 [==============================] - 0s 121us/step - loss: 0.3218 - accuracy: 0.8919 - val_loss: 0.4264 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.42731 to 0.42640, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 71/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.3088 - accuracy: 0.8872 - val_loss: 0.4212 - val_accuracy: 0.8436\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.42640 to 0.42117, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 72/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.3270 - accuracy: 0.8729 - val_loss: 0.4179 - val_accuracy: 0.8436\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.42117 to 0.41789, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 73/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3040 - accuracy: 0.9002 - val_loss: 0.4174 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.41789 to 0.41743, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 74/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.3194 - accuracy: 0.8943 - val_loss: 0.4118 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.41743 to 0.41176, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 75/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.3134 - accuracy: 0.9014 - val_loss: 0.4107 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.41176 to 0.41070, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 76/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.3116 - accuracy: 0.8919 - val_loss: 0.4119 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.41070\n",
            "Epoch 77/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.2978 - accuracy: 0.9026 - val_loss: 0.4066 - val_accuracy: 0.8673\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.41070 to 0.40664, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 78/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.2981 - accuracy: 0.8931 - val_loss: 0.4067 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.40664\n",
            "Epoch 79/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.2872 - accuracy: 0.9097 - val_loss: 0.4017 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.40664 to 0.40173, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 80/250\n",
            "842/842 [==============================] - 0s 108us/step - loss: 0.2811 - accuracy: 0.9192 - val_loss: 0.3999 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.40173 to 0.39991, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 81/250\n",
            "842/842 [==============================] - 0s 123us/step - loss: 0.2706 - accuracy: 0.9192 - val_loss: 0.3972 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.39991 to 0.39718, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 82/250\n",
            "842/842 [==============================] - 0s 120us/step - loss: 0.2916 - accuracy: 0.9026 - val_loss: 0.3982 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.39718\n",
            "Epoch 83/250\n",
            "842/842 [==============================] - 0s 137us/step - loss: 0.2827 - accuracy: 0.9157 - val_loss: 0.3947 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.39718 to 0.39467, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 84/250\n",
            "842/842 [==============================] - 0s 119us/step - loss: 0.2869 - accuracy: 0.9086 - val_loss: 0.3928 - val_accuracy: 0.8673\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.39467 to 0.39284, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 85/250\n",
            "842/842 [==============================] - 0s 122us/step - loss: 0.2682 - accuracy: 0.9145 - val_loss: 0.3904 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.39284 to 0.39037, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 86/250\n",
            "842/842 [==============================] - 0s 122us/step - loss: 0.2626 - accuracy: 0.9145 - val_loss: 0.3921 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.39037\n",
            "Epoch 87/250\n",
            "842/842 [==============================] - 0s 119us/step - loss: 0.2693 - accuracy: 0.9109 - val_loss: 0.3870 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.39037 to 0.38698, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 88/250\n",
            "842/842 [==============================] - 0s 109us/step - loss: 0.2642 - accuracy: 0.9157 - val_loss: 0.3844 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.38698 to 0.38441, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 89/250\n",
            "842/842 [==============================] - 0s 111us/step - loss: 0.2456 - accuracy: 0.9240 - val_loss: 0.3840 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.38441 to 0.38405, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 90/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.2520 - accuracy: 0.9145 - val_loss: 0.3859 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.38405\n",
            "Epoch 91/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.2490 - accuracy: 0.9133 - val_loss: 0.3846 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.38405\n",
            "Epoch 92/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.2453 - accuracy: 0.9216 - val_loss: 0.3847 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.38405\n",
            "Epoch 93/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.2316 - accuracy: 0.9240 - val_loss: 0.3860 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.38405\n",
            "Epoch 94/250\n",
            "842/842 [==============================] - 0s 115us/step - loss: 0.2434 - accuracy: 0.9252 - val_loss: 0.3809 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.38405 to 0.38087, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 95/250\n",
            "842/842 [==============================] - 0s 103us/step - loss: 0.2500 - accuracy: 0.9097 - val_loss: 0.3810 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.38087\n",
            "Epoch 96/250\n",
            "842/842 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.9252 - val_loss: 0.3816 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.38087\n",
            "Epoch 97/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.2223 - accuracy: 0.9287 - val_loss: 0.3803 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.38087 to 0.38035, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 98/250\n",
            "842/842 [==============================] - 0s 109us/step - loss: 0.2322 - accuracy: 0.9347 - val_loss: 0.3787 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.38035 to 0.37868, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 99/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.2252 - accuracy: 0.9371 - val_loss: 0.3776 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.37868 to 0.37763, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 100/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.2200 - accuracy: 0.9323 - val_loss: 0.3776 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.37763 to 0.37760, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 101/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.2037 - accuracy: 0.9335 - val_loss: 0.3752 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.37760 to 0.37524, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 102/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.2016 - accuracy: 0.9406 - val_loss: 0.3768 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.37524\n",
            "Epoch 103/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.2311 - accuracy: 0.9228 - val_loss: 0.3763 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.37524\n",
            "Epoch 104/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.2353 - accuracy: 0.9121 - val_loss: 0.3741 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.37524 to 0.37405, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 105/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.2133 - accuracy: 0.9264 - val_loss: 0.3751 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.37405\n",
            "Epoch 106/250\n",
            "842/842 [==============================] - 0s 102us/step - loss: 0.2184 - accuracy: 0.9371 - val_loss: 0.3752 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.37405\n",
            "Epoch 107/250\n",
            "842/842 [==============================] - 0s 117us/step - loss: 0.2151 - accuracy: 0.9406 - val_loss: 0.3763 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.37405\n",
            "Epoch 108/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.2031 - accuracy: 0.9382 - val_loss: 0.3756 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.37405\n",
            "Epoch 109/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.1886 - accuracy: 0.9477 - val_loss: 0.3713 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.37405 to 0.37128, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 110/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.1978 - accuracy: 0.9299 - val_loss: 0.3764 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.37128\n",
            "Epoch 111/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.2000 - accuracy: 0.9347 - val_loss: 0.3767 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.37128\n",
            "Epoch 112/250\n",
            "842/842 [==============================] - 0s 110us/step - loss: 0.1800 - accuracy: 0.9418 - val_loss: 0.3731 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.37128\n",
            "Epoch 113/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.1832 - accuracy: 0.9371 - val_loss: 0.3709 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.37128 to 0.37089, saving model to lnr-cp-sqr01.h5\n",
            "Epoch 114/250\n",
            "842/842 [==============================] - 0s 112us/step - loss: 0.1969 - accuracy: 0.9335 - val_loss: 0.3783 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.37089\n",
            "Epoch 115/250\n",
            "842/842 [==============================] - 0s 108us/step - loss: 0.1894 - accuracy: 0.9418 - val_loss: 0.3740 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.37089\n",
            "Epoch 116/250\n",
            "842/842 [==============================] - 0s 106us/step - loss: 0.1776 - accuracy: 0.9477 - val_loss: 0.3843 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.37089\n",
            "Epoch 117/250\n",
            "842/842 [==============================] - 0s 105us/step - loss: 0.1857 - accuracy: 0.9394 - val_loss: 0.3749 - val_accuracy: 0.9052\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.37089\n",
            "Epoch 118/250\n",
            "842/842 [==============================] - 0s 112us/step - loss: 0.1772 - accuracy: 0.9513 - val_loss: 0.3729 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.37089\n",
            "Epoch 119/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.1776 - accuracy: 0.9513 - val_loss: 0.3730 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.37089\n",
            "Epoch 120/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.1857 - accuracy: 0.9382 - val_loss: 0.3756 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.37089\n",
            "Epoch 121/250\n",
            "842/842 [==============================] - 0s 107us/step - loss: 0.1827 - accuracy: 0.9382 - val_loss: 0.3816 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.37089\n",
            "Epoch 122/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.1805 - accuracy: 0.9418 - val_loss: 0.3731 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.37089\n",
            "Epoch 123/250\n",
            "842/842 [==============================] - 0s 104us/step - loss: 0.1738 - accuracy: 0.9442 - val_loss: 0.3728 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.37089\n",
            "Epoch 00123: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYxomr9mZ_kR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e4581e5f-8376-4d59-83d4-0f7f286be07d"
      },
      "source": [
        "sqr_model = tf.python.keras.models.load_model('lnr-cp-sqr01.h5')\n",
        "adam_predictions = sqr_model.predict(X_test, verbose=1)\n",
        "# prediction and clasification report\n",
        "y_true, y_pred = [],[]\n",
        "#classes = le.classes_\n",
        "\n",
        "for idx, prediction in enumerate(adam_predictions): \n",
        "    y_true.append([np.argmax(y_test[idx])])\n",
        "    y_pred.append([np.argmax(prediction)])\n",
        "    \n",
        "print(sklearn.metrics.classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89        60\n",
            "           1       0.89      0.86      0.88        57\n",
            "\n",
            "    accuracy                           0.88       117\n",
            "   macro avg       0.88      0.88      0.88       117\n",
            "weighted avg       0.88      0.88      0.88       117\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-0Wa00oVc5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "15c88410-bc99-4ad3-901e-34181bb3fd15"
      },
      "source": [
        "files.download('lnr-cp-sqr01.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b4371ee9-f062-461e-97c6-2e0b72ea5772\", \"lnr-cp-sqr01.h5\", 136072)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}