{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing regression_CP.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3TUJShYLjqgX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1597315782974,"user_tz":-60,"elapsed":3125,"user":{"displayName":"YUEWEN LI","photoUrl":"","userId":"15636031451830471650"}},"outputId":"424efc46-f12a-40fb-fa65-462d219ad5f1"},"source":["from sklearn import preprocessing\n","from sklearn.preprocessing import (LabelEncoder, KBinsDiscretizer, StandardScaler, MinMaxScaler)\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from keras.layers.core import Dense, Activation, Dropout\n","from keras.optimizers import Adam, Nadam\n","from sklearn.utils import class_weight\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from keras.callbacks import ModelCheckpoint\n","import imblearn\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.over_sampling import BorderlineSMOTE\n","from sklearn.metrics import confusion_matrix\n","import sklearn\n","import tensorflow as tf\n","from google.colab import files\n","import pickle\n","from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV)\n","from sklearn.datasets import make_classification\n","from sklearn.ensemble import (GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor)\n","from imblearn.over_sampling import SMOTE\n","import collections\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import cross_val_score\n","from pandas import DataFrame\n","from sklearn.cluster import KMeans\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","from sklearn import tree\n","\n","import warnings\n","import sys\n","\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Me4Vt8rjoYoO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1597315810078,"user_tz":-60,"elapsed":19806,"user":{"displayName":"YUEWEN LI","photoUrl":"","userId":"15636031451830471650"}},"outputId":"7b4c58be-0f84-4212-b928-bb78b20d211e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L0PoIsXDb_Bj","colab_type":"code","colab":{}},"source":["def get_data(list_of_files):\n","  X_ls = []\n","  Y_ls = []\n","  \n","  for filename in list_of_files:\n","    if filename[-1] == 'x':\n","      df = pd.read_excel(filename)\n","    else:\n","      df = pd.read_csv(filename)\n","    df = df.dropna()\n","\n","    # getting Y_ls\n","    Y = df.iloc[:,-1]\n","    Y = np.array(Y).reshape(-1, 1)\n","    scaler = MinMaxScaler()\n","    Y = pd.DataFrame(scaler.fit_transform(Y))\n","    Y_ls.append(Y)\n","\n","    # getting X_ls\n","    X = df.iloc[:, :-1]\n","    X = X._get_numeric_data()\n","    X_ls.append(X)\n","\n","  return(X_ls,Y_ls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnPp_080wBID","colab_type":"code","colab":{}},"source":["import glob\n","test_files = glob.glob('/content/drive/My Drive/TESTING DATASETS/reg_testing_datasets/*.csv')\n","test_files_xlsx = glob.glob('/content/drive/My Drive/TESTING DATASETS/reg_testing_datasets/*.xlsx')\n","test_files.extend(test_files_xlsx) \n","\n","X_ls, Y_ls = get_data(test_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSLf0ls7yXLE","colab_type":"code","colab":{}},"source":["# prepare test data\n","\n","def scale(variable):\n","  \"\"\"Scales the original variable from 0 to 1\"\"\"\n","  data = np.array(variable).reshape(-1,1)\n","  scaled_data = preprocessing.MinMaxScaler().fit_transform(data)\n","  scaled_data = pd.DataFrame(data = scaled_data)\n","  scaled_data = scaled_data.copy()\n","  return(scaled_data)\n","\n","def scale_data(X):\n","  '''\n","  scale the test data\n","  '''\n","  scaled_X = preprocessing.MinMaxScaler().fit_transform(X)\n","  X = pd.DataFrame(data = scaled_X, columns = X.columns)\n","\n","  return X\n","\n","def ranging(variable, bins):\n","  quantiles_list = []\n","  quantiles = make_seq(inc=bins)\n","  for i in quantiles:\n","    quantiles_list.append(np.percentile(variable, i))\n","  return(quantiles_list)\n","\n","def make_seq(inc):\n","  x = []\n","  start = 0\n","  end = 100\n","\n","  while start < end:\n","    start += inc \n","    start = round(start,2)\n","    x.append(start)\n","  return(x)\n","\n","# CP method: creating feature representation of a dataset\n","def conditional_binning(data,Y,X_q,Y_q):\n","  FXY = []\n","  FY = []\n","\n","  oldy_q = 0\n","  for y_q in Y_q:\n","    if oldy_q == 0:\n","      count = sum(1 for y in Y if y <= y_q and y >= oldy_q )\n","    else:\n","      count = sum(1 for y in Y if y <= y_q and y > oldy_q )\n","    oldy_q = y_q\n","    FY.append(count)\n","\n","\n","  oldx_q = 0\n","  for x_q in X_q:\n","    oldy_q = 0\n","    for i,y_q in enumerate(Y_q):\n","      \n","      if oldx_q == 0 and oldy_q == 0:\n","        count = sum(1 for i in range(0,len(data)) if data[i] <= x_q and data[i] >= oldx_q and Y[i] <= y_q and Y[i] >= oldy_q )\n","        \n","      elif oldx_q == 0:\n","        count = sum(1 for i in range(0,len(data)) if data[i] <= x_q and data[i] >= oldx_q and Y[i] <= y_q and Y[i] > oldy_q )\n","        \n","      elif oldy_q == 0:\n","        count = sum(1 for i in range(0,len(data)) if data[i] <= x_q and data[i] > oldx_q and Y[i] <= y_q and Y[i] >= oldy_q )\n","        \n","      else:\n","        count = sum(1 for i in range(0,len(data)) if data[i] <= x_q and data[i] > oldx_q and Y[i] <= y_q and Y[i] > oldy_q )\n","      if FY[i] != 0:\n","        FXY.append(count/FY[i])\n","      else:\n","        FXY.append(0)\n","      oldy_q = y_q\n","    oldx_q = x_q\n","\n","  return(FXY)\n","\n","def conditional_binning(data,Y,X_q,Y_q):\n","  FXY = []\n","  FY = []\n","\n","  for y_q in Y_q:\n","    count = sum(1 for y in Y if y <= y_q )\n","    FY.append(count)\n","\n","  for x_q, i, y_q in [(x_q, i, y_q) for x_q in X_q for i, y_q in enumerate(Y_q)]:\n","    count = sum(1 for x,y in zip(data, Y) if x <= x_q and y <= y_q)\n","        \n","    if FY[i] != 0:\n","      FXY.append(count/FY[i])\n","    else:\n","      FXY.append(0)\n","      \n","\n","  return(FXY)\n","  \n","def binning(features_list, data, y):\n","    \n","  b = {\"bin_edges\":[]}\n","\n","  y = y[0].to_list()\n","  Y_q = ranging(y,5)\n","\n","  for feature in features_list:\n","\n","    data_feature = list(data[feature])\n","    data_feature = scale(data_feature)\n","    data_feature = data_feature[0].to_list()\n","    \n","    X_q = ranging(data_feature,5)\n","    \n","    bin = conditional_binning(data_feature,y,X_q,Y_q)\n","\n","    b[\"bin_edges\"].append(bin) \n","    \n","  training_data = np.array(b[\"bin_edges\"])\n"," \n","  return(training_data)\n","  \n","def create_testdata(X, Y):\n","  '''\n","  return test data to be fed into mlps\n","  '''\n","  test_data = []\n","  \n","  features_list = X.columns\n","  test = binning(features_list, X, Y)\n","  test_data.extend(test)\n","  \n","  return test_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"en8UQ6rrHrmS","colab_type":"text"},"source":["# Output recommendation results"]},{"cell_type":"markdown","metadata":{"id":"u4TTvpghysC4","colab_type":"text"},"source":["### output all transformations per dataset"]},{"cell_type":"code","metadata":{"id":"GejD7UzYlwSU","colab_type":"code","colab":{}},"source":["# recommend all\n","def recommend(path, X, Y):\n","  # iterate over all models\n","  models_ls = glob.glob(path)\n","\n","  # res = []\n","\n","  test_new = X.copy()\n","  # for one test data\n","  test_data = create_testdata(X, Y)\n","\n","  colnames = X.columns\n","  \n","  row = []\n","  scores = []\n","\n","  for m in models_ls:\n","    row.append(m.split('/')[-1][:-3])\n","    model = tf.python.keras.models.load_model(m)\n","    pred = model.predict(np.array(test_data), verbose=1)\n","    # the score for positive label\n","    scores.append(pred[:,1])\n","\n","  result = pd.DataFrame(scores, columns = colnames, index = row)\n","  \n","  # print(result.head())\n","  # print('Recommended transformation for ',test_files[i].split('/')[-1][:-4])\n","  # print('\\n')\n","\n","  dict_ = {}\n","\n","  cnt = 0\n","  \n","  for col in colnames:\n","    sorted_result = result.sort_values(axis = 0, by = col, ascending = False)\n","    rcm_trans = sorted_result[sorted_result[col] >= 0.5].index.tolist()\n","    dict_[col] = rcm_trans\n","    print(col+': ',rcm_trans)\n","    if len(rcm_trans) > 0:\n","      cnt += 1\n","\n","  # if cnt == 0:\n","  #   print('No transformation is recommended for this dataset!!!')\n","    \n","  # res.append(dict_)\n","  \n","  # print('\\n')\n","\n","  return dict_, cnt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dt7ruIxAGAge","colab_type":"code","colab":{}},"source":["# classifiers\n","def linear_regression(x_var, y_var):\n","  X_train, X_test, y_train, y_test = train_test_split(x_var, y_var, test_size=0.2, random_state=0)\n","  lr = LinearRegression()  \n","  lr.fit(X_train, y_train)\n","  y_pred = lr.predict(X_test)\n","  score = metrics.r2_score(y_test, y_pred)\n","  return(score)\n","\n","def decision_tree(x_var, y_var):\n","  X_train, X_test, y_train, y_test = train_test_split(x_var, y_var, test_size=0.2, random_state=0)\n","  clf = tree.DecisionTreeRegressor(random_state=0)\n","  clf.fit(X_train,y_train)\n","  y_pred = clf.predict(X_test)\n","  score = metrics.r2_score(y_test, y_pred)\n","  return(score)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SSpzjRtixWUD","colab_type":"text"},"source":["## Replace features"]},{"cell_type":"code","metadata":{"id":"vBs_kywzVn6F","colab_type":"code","colab":{}},"source":["# transformations\n","def freq(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  given_feature = data_new[feature]\n","  frequency = collections.Counter(given_feature) \n","  transformed_feature = [frequency[x] for x in given_feature] \n","  data_new[feature] = transformed_feature\n","  return(data_new)\n","\n","def sq(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = transformed_feature**2\n","  data_new[feature] = transformed_feature\n","  return(data_new)\n","\n","def sqr(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = abs(transformed_feature)\n","  transformed_feature = np.sqrt(transformed_feature)\n","  data_new[feature] = transformed_feature\n","  return(data_new)\n","\n","def log(data, feature):\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = abs(transformed_feature)\n","  transformed_feature = np.where(transformed_feature == 0, 1e-9, transformed_feature)\n","  transformed_feature = np.log(transformed_feature)\n","  data_new[feature] = transformed_feature\n","  return(data_new)\n","\n","def sigmoid(data, feature):\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = 1/(1 + np.exp(-transformed_feature))\n","  data_new[feature] = transformed_feature\n","  return(data_new)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Z4C5exsxaQK","colab_type":"text"},"source":["## Add features"]},{"cell_type":"code","metadata":{"id":"7WG1Kl_exU_J","colab_type":"code","colab":{}},"source":["# transformations\n","def freq_add(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  given_feature = data_new[feature]\n","  frequency = collections.Counter(given_feature) \n","  transformed_feature = [frequency[x] for x in given_feature] \n","  feature_new = feature+'_new'\n","  data_new[feature_new] = transformed_feature\n","  return(data_new)\n","\n","def sq_add(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = transformed_feature**2\n","  feature_new = feature+'_new'\n","  data_new[feature_new] = transformed_feature\n","  return(data_new)\n","\n","def sqr_add(data, feature):\n","  \"\"\"convert the feature values to absolute value and then take the square root\"\"\"\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = abs(transformed_feature)\n","  transformed_feature = np.sqrt(transformed_feature)\n","  feature_new = feature+'_new'\n","  data_new[feature_new] = transformed_feature\n","  return(data_new)\n","\n","def log_add(data, feature):\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = abs(transformed_feature)\n","  transformed_feature = np.where(transformed_feature == 0, 1e-9, transformed_feature)\n","  transformed_feature = np.log(transformed_feature)\n","  feature_new = feature+'_new'\n","  data_new[feature_new] = transformed_feature\n","  return(data_new)\n","\n","def sigmoid_add(data, feature):\n","  data_new = data.copy()\n","  transformed_feature = data_new[feature]\n","  transformed_feature = 1/(1 + np.exp(-transformed_feature))\n","  feature_new = feature+'_new'\n","  data_new[feature_new] = transformed_feature\n","  return(data_new)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CdqPxJZ8H7nE","colab_type":"text"},"source":["# Apply transformations"]},{"cell_type":"code","metadata":{"id":"eqJr4DBewDvP","colab_type":"code","colab":{}},"source":["def apply_trans(dict_, X, Y, add):\n","\n","  score_before_ls = []\n","  score_after_ls = []\n","  diff_ls = []\n","  file_ls = []\n","  \n","  test_original = X.copy()\n","  label = Y\n","\n","  test_original = scale_data(test_original)\n","\n","  colnames = X.columns\n","\n","  # apply transformation\n","  if add == True:\n","    methods = {'sq': sq_add, 'sqr':sqr_add, 'freq':freq_add, 'log':log_add, 'sig': sigmoid_add}\n","  else:\n","    methods = {'sq': sq, 'sqr':sqr, 'freq':freq, 'log':log, 'sig': sigmoid}\n","  test_new = test_original.copy()\n","\n","  # dict_ = res[i]\n","  \n","  '''\n","  for col in colnames:\n","    if len(dict_[col]) > 0:\n","      for i in dict_[col]:\n","        test_new = methods[i](test_new, col)\n","      test_new.drop(columns=[col],inplace = True)\n","  '''\n","  for col in colnames:\n","    if len(dict_[col]) > 0:\n","      test_new = methods[dict_[col][0]](test_new, col)  \n","  \n","\n","  '''\n","  # corresponding to one transformation per dataset\n","  col = list(dict_.keys())[0]\n","  test_new = methods[dict_[col]](test_new, col)\n","  '''\n","\n","  return test_new, label\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpCI3Rw9HoV-","colab_type":"code","colab":{}},"source":["def eval(avg, file_name, test_original, test_new, label, *args):\n","\n","  if avg == True:\n","    score_lnr0 = linear_regression(test_original, label)\n","    score_dtr0 = decision_tree(test_original, label)\n","    \n","    score_before = (score_lnr0 + score_dtr0) / 2\n","\n","    score_lnr1 = linear_regression(test_new, label)\n","    score_dtr1 = decision_tree(test_new, label)\n","    \n","    score_after = (score_lnr1 + score_dtr1) / 2\n","\n","  else:\n","    model = args[0]\n","    if model == 'lnr':\n","      score_before = linear_regression(test_original, label)\n","      score_after = linear_regression(test_new, label)\n","\n","    elif model == 'dtr':\n","      score_before = decision_tree(test_original, label)\n","      score_after = decision_tree(test_new, label)\n","  \n","  if score_after > score_before:\n","    improve = ' improved'\n","  else:\n","    improve = ' not improved'\n","\n","  diff = score_after - score_before\n","\n","  print(file_name, ' original score: ',score_before,'; score after: ',score_after, '; difference: ', diff ,improve)\n","  # print(test_files[i].split('/')[-1][:-4], improve)\n","\n","  return score_before, score_after, diff, file_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ch9UHBq1G0EW","colab_type":"code","colab":{}},"source":["# combination of trasformations\n","def multiple_testing(path, n, add, model):\n","  score_before_ls = []\n","  score_after_ls = []\n","  diff_ls = []\n","  file_ls = []\n","\n","  for i in range(len(test_files)):\n","    X = X_ls[i].copy()\n","    Y = Y_ls[i].copy()\n","    X_origin = scale_data(X)\n","    for j in range(n):\n","      res, cnt = recommend(path, X, Y)\n","      if cnt > 0:\n","        X_new, Y = apply_trans(res, X, Y, add)\n","        X = X_new\n","      else:\n","        X = X_origin\n","    score_before, score_after, diff, file = eval(False, test_files[i].split('/')[-1][:-4], X_origin, X, Y, model)\n","    #if score_before <= 0.999 and score_before > 0:\n","    score_before_ls.append(score_before)\n","    score_after_ls.append(score_after)\n","    diff_ls.append(score_after - score_before)\n","    file_ls.append(test_files[i].split('/')[-1][:-4])\n","\n","  return score_before_ls, score_after_ls, diff_ls, file_ls\n"],"execution_count":null,"outputs":[]}]}